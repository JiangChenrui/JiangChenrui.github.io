<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Residual Attention Network]]></title>
    <url>%2F2019%2F03%2F18%2FResidual-Attention-Network%2F</url>
    <content type="text"><![CDATA[摘要&emsp;&emsp;在这个工作中，我们提出了“残差注意网络”，它是一种使用注意力机制的卷积神经网络，能够将最先进的前馈神经网络机制融合到端对端的训练中。我们的残差注意网络是由生成注意力感知特征的注意力模块堆叠而成的。注意力感知特征会随着层数的加深自适应地改变。在每个注意力模块的内部，自上而下自下而上的前馈结构能够将前馈和反馈结构展开到单个的前馈过程中。重要的事，我们提出的注意力残差学习非常深的残差注意网络，能够轻松地扩展到数百层。&emsp;&emsp;我们对CIFAR-10和CIFAR-100数据集进行了广泛的分析，以验证上述每个模块的有效性。我们的剩余注意力网络在三个基准数据集上实现了最先进的物体识别性能，包括CIFAR-10（3.90％误差），CIFAR-100（20.45％误差）和ImageNet（4.8％单一模型和单一作物，顶部 - 5错误）。请注意，与ResNet-200相比，我们的方法实现了0.6％的前1精度提升，46％的主干深度和69％的前向FLOP。该实验还表明，我们的网络可以抵御嘈杂的标签。 1 介绍&emsp;&emsp;]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>attention</tag>
        <tag>图像分类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Domain Separation Networks]]></title>
    <url>%2F2019%2F03%2F18%2FDomain-Separation-Networks%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[神经网络结构汇总]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[本文收集了一些神经网络的架构，包含常用的一些模型。 LeNet51.Input&emsp;&emsp;输入图像统一归一化为32*32。2.C1卷积层&emsp;&emsp;经过(5*5*1)*6卷积核，stride=1, 生成featuremap为28*28*6。3.S2池化层&emsp;&emsp;经过(2*2)采样核，stride=2，生成featuremap为14*14*6。4.C3卷积层&emsp;&emsp;经过(5*5*6)*16卷积核，stride=1，生成featuremap为10*10*16。5.S4池化层&emsp;&emsp;经过(2*2)采样核，stride=2，生成featuremap为5*5*16。6.C5卷积层&emsp;&emsp;经过(5*5*16)*120卷积核，stride=1， 生成featuremap为1*1*120。7.F6全连接层&emsp;&emsp;输入为1*1*120，输出为1*1*84，总参数量为120*84。8.Output全连接层。&emsp;&emsp;输入为1*1*84，输出为1*1*10，总参数量为84*10。10就是分类的类别数。 AlexNet1.Input&emsp;&emsp;输入图像为227*227*3。2.Conv1&emsp;&emsp;经过(11*11*3)*96卷积核，stride=4， (227-11)/4+1=55，生成featuremap为55*55*96。3.Pool1&emsp;&emsp;经过3*3的池化核，stride=2，(55-3)/2+1=27，生成featuremap为27*27*96。4.Norm1&emsp;&emsp;local_size=5，生成featuremap为27*27*96。5.Conv2&emsp;&emsp;经过(5*5*96)*256的卷积核，pad=2，group=2，(27+2*2-5)/1+1=27，生成featuremap为27*27*256。6.Pool2&emsp;&emsp;经过3*3的池化核，stride=2，(27-3)/2+1=13，生成featuremap为13*13*256。7.Norm2&emsp;&emsp;local_size=5, 生成featuremap为13*13*256。8.Conv3&emsp;&emsp;经过(3*3*256)*384卷积核，pad=1， (13+1*2-3)/1+1=13，生成featuremap为13*13*384。9.Conv4&emsp;&emsp;经过(3*3*384)*384卷积核，pad=1，(13+1*2-3)/1+1=13，生成featuremap为13*13*384。10.Conv5&emsp;&emsp;经过(3*3*384)*256卷积核，pad=1，(13+1*2-3)/1+1=13，生成featuremap为13*13*256。11.Pool5&emsp;&emsp;经过(3*3)的池化核，stride=2，(13-3)/2+1=6，生成featuremap为6*6*256。12.Fc6&emsp;&emsp;输入为(6*6*256)*4096全连接，生成featuremap为1*1*4096。13.Dropout6&emsp;&emsp;在训练的时候以1/2概率使得隐藏层的某些神经元的输出为0，这样就丢掉了一半节点的输出，BP的时候也不更新这些节点，以下Droupout同理。14.Fc7&emsp;&emsp;输入为1*1*4096，输出为1*1*4096，总参数量为4096*4096。15.Dropout7&emsp;&emsp;生成featuremap为1*1*4096。16.Fc8&emsp;&emsp;输入为1*1*4096，输出为1000，总参数量为4096*1000。 总结: 1.网络比LeNet更深，包括5个卷积层和3个全连接层。2.使用relu激活函数，收敛很快，解决了Sigmoid在网络较深时出现的梯度弥散问题。3.加入了dropout层，防止过拟合。4.使用了LRN归一化层，对局部神经元的活动创建竞争机制，抑制反馈较小的神经元放大反应大的神经元，增强了模型的泛化能力。5.使用裁剪翻转等操作做数据增强，增强了模型的泛化能力。预测时使用提取图片四个角加中间五个位置并进行左右翻转一共十幅图片的方法求取平均值，这也是后面刷比赛的基本使用技巧。6.分块训练，当年的GPU没有这么强大，Alexnet创新地将图像分为上下两块分别训练，然后在全连接层合并在一起。7.总体的数据参数大概为240M。 VGG 1.Input层&emsp;&emsp;输入图片为224*224*3。2.CONV3-64&emsp;&emsp;经过（3*3*3）*64卷积核，生成featuremap为224*224*64。3.CONV3-64&emsp;&emsp;经过（3*3*64）*64卷积核，生成featuremap为224*224*64。4.Max pool&emsp;&emsp;经过（2*2）max pool核，生成featuremap为112*112*64。5.CONV3-128。&emsp;&emsp;经过（3*3*64）*128卷积核，生成featuremap为112*112*128。6.CONV3-128&emsp;&emsp; 经过（3*3*128）*128卷积，生成featuremap为112*112*128。7.Max pool&emsp;&emsp;经过（2*2）maxpool，生成featuremap为56*56*128。8.CONV3-256&emsp;&emsp;经过（3*3*128）*256卷积核，生成featuremap为56*56*256。9.CONV3-256&emsp;&emsp;经过（3*3*256）*256卷积核，生成featuremap为56*56*256。10.CONV3-256&emsp;&emsp;经过（3*3*256）*256卷积核，生成featuremap为56*56*256。11.Max pool&emsp;&emsp;经过（2*2）maxpool，生成featuremap为28*28*256。12.CONV3-512&emsp;&emsp;经过（3*3*256）*512卷积核，生成featuremap为28*28*512。13.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为28*28*512。14.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为28*28*512。15.Max pool&emsp;&emsp;经过（2*2）maxpool,生成featuremap为14*14*512。16.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为14*14*512。17.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为14*14*512。18.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为14*14*512。19.Max pool&emsp;&emsp;经过2*2卷积，生成featuremap为7*7*512。20.FC-4096&emsp;&emsp;输入为7*7*512，输出为1*1*4096，总参数量为7*7*512*4096。21.FC-4096&emsp;&emsp;输入为1*1*4096，输出为1*1*4096，总参数量为4096*4096。22.FC-1000&emsp;&emsp;输入为1*1*4096，输出为1000，总参数量为4096*1000。 总结: 1. 共包含参数约为550M。2. 全部使用3*3的卷积核和2*2的最大池化核。3. 简化了卷积神经网络的结构。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习，计算机视觉，CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将博客搬至CSDN]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%B0%86%E5%8D%9A%E5%AE%A2%E6%90%AC%E8%87%B3CSDN%2F</url>
    <content type="text"><![CDATA[尝试将个人博客搬到CSDN]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试问题收集]]></title>
    <url>%2F2019%2F01%2F23%2F%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[GItHub使用指南GitHub 编辑指导GItHub 公式编辑Markdown 教程 计算机视觉面试问题SVMCNN常见网络收集 softmax函数attentiondata augmentation正则化泰勒公式Batch Normalization网络参数是如何计算的ShuffleNetdeepwise separable conv最优化方法深度神经网络全面概述：从基本概念到实际模型和硬件基础1.数学概念 RNNLSTMRPNPCAK_meansKNN损失函数梯度消失和梯度弥散SITFDropoutPooling正则化数据结构和算法问题线性代数堆和栈的区别计算机视觉及深度学习岗位应聘问题]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>计算机视觉</tag>
        <tag>面试</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode刷题总结]]></title>
    <url>%2F2019%2F01%2F23%2FLeetCode%E5%88%B7%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1 数组用法123456789101112//元素交换swap(a[1], a[3]);//sort排序sort(a.begin(),a.end());//数组颠倒reverse(a.begin(), a.end());//数组元素置为0memset(a, 0, a.size());//数组取值a.push_back();//定义二维数组vector&lt; vector&lt;int&gt; &gt; result 2 set集合的用法集合中没有重复元素 12345678910111213141516//定义一个int类型的集合set&lt;int&gt; s;set&lt;int&gt;::iterator it;//插入元素10（插入的数值默认从小到大排序）s.insert(10);//删除元素10s.erase(10);//清空集合s.clear();//集合元素的个数s.size();//判断集合是否为空s.empty();//查找集合中是否与元素10，有的话返回10，没有则返回s.end()it = s.find(10);// mutiset：多重集合与set最大的区别是它可以插入重复元素，如果删除的话，相同的会一起删除，如果查找的话，返回该元素的迭代器的位置，若有相同，返回第一个元素的地址，其它使用和set基本类似。 3 map用法c++中map中的元素按key升序排列，基本格式为map m，需要使用头文件#include。 12345//数据的插入map&lt;int, string&gt; studentsID;studentsID.instert(pair&lt;int, string&gt;(1, "student_one"));studentsID.instert(map&lt;int, string&gt;::value_type(2, "student_two"));studentID[3]="student_three"; 4 字符串12345678//排序sort(a.begin(), a.end());//将所有字符转换成小写transform(s.begin(), s.end(), s.begin(),::tolower);//截取字符串//标准库的string有一个substr函数用来截取子字符串。一般使用时传入两个参数，第一个是开始的坐标（第一个字符是0），第二个是截取的长度。string name("rockderia");string firstname(name.substr(0,4)); 5 运算异或（^）：二进制数进行运算相同为0，不同为1与运算（&amp;）：同时为1，才为1；或运算（|）：同时为0，才为0；取反（~）左移（&lt;&lt;）：左边的二进制丢失，右边补0，左移最高位不包括1，左移相当于该数乘2；右移（&gt;&gt;）:正数左补0，负数左补1不同长度的数据进行位运算时，系统会自动补齐。 6 栈栈具有先进后出的特性 123456789101112131415// 默认构造函数stack&lt;int&gt; s;// 复制构造函数stack&lt;int, list&lt;int&gt;&gt; s1;stack&lt;int, list&lt;int&gt;&gt; s2(s1);// 入栈s.push();// 出栈，不会显示内容s.pop();// 提取栈顶元素s.top();// 判断是否非空s.empty() // true表示未空，false表示非空// 返回栈中数目s.size() 7 队列1234567891011121314// 定义队列queue&lt;int&gt; q;// 入队q.push(x)// 出队q.pop()// 访问队首元素q.front()// 访问队尾元素q.back()// 判断队列是否为空q.empty()// 访问队列中元素个数q.size() 队列具有先进先出的特性]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>LeetCode</tag>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy.random函数的一些用法]]></title>
    <url>%2F2019%2F01%2F23%2Fnumpy-random%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考博客 numpy.random.rand()numpy.random.rand(d0, d1, …, dn) rand函数根据给定维度生成[0,1)之间的数据，包含0，不包含1 dn表示每个维度 返回值为指定维度的array 输入 1np.random.rand(4, 2) # 生成4行两列0-1之间的随机数 输出 1234array([[ 0.2639652 , 0.67762924], [ 0.50164586, 0.73739781], [ 0.18457953, 0.85558988], [ 0.16193526, 0.83935579]]) 输入 1np.random.rand(4, 3, 2) # shape为[4, 3, 2] 输出 123456789101112131415array([[[ 0.49636822, 0.89954378], [ 0.5711387 , 0.41691163], [ 0.05681485, 0.88512829]], [[ 0.88798283, 0.96294557], [ 0.91100035, 0.28982022], [ 0.90098484, 0.85539872]], [[ 0.99124126, 0.87069271], [ 0.82365864, 0.33025856], [ 0.8874623 , 0.22067393]], [[ 0.62666929, 0.71956291], [ 0.81974729, 0.46510244], [ 0.03494486, 0.11045034]]]) numpy.random.randn()numpy.random.randn(d0,d1,…,dn) randn函数返回一个或一组样本，具有标准正态分布. dn表示每个维度 返回值为指定维度的array 标准正态分布是以0为均值，1为标准差的正态分布，记为N(0, 1)。 1np.random.randn(4, 2) 1-0.599153380810341 1np.random.randn(4, 2) 1234array([[-0.83173279, -0.06084999], [ 0.30143042, -0.63863605], [-0.45491282, 0.72084355], [-0.86603523, 1.14210338]]) 1np.random.randn(4, 3, 2) 123456789101112131415array([[[ 0.62674807, -0.40911062], [-0.65785551, 0.85653665], [-0.55250578, 1.15478597]], [[-1.39797824, 1.36343765], [-0.35807181, 2.08002524], [-0.16746821, 1.89978231]], [[-0.89490747, -0.49563846], [ 0.36720155, -0.30631295], [ 0.43208381, 1.04328295]], [[-0.65629808, 0.501748 ], [ 0.30889304, -0.52872014], [ 0.04584062, -0.05242994]]]) numpy.random.randint()numpy.random.randint(low, high=None, size=None, dtype=’l’) 返回随机整数，范围区间为[low,high），包含low，不包含high 参数：low为最小值，high为最大值，size为数组维度大小，dtype为数据类型，默认的数据类型是np.int high没有填写时，默认生成随机数的范围是[0，low) 1np.random.randint(1, size=5) 1array([0, 0, 0, 0, 0]) 1np.random.randint(1, 5) 12 1np.random.randint(-5, 5, size=[2,2]) 12array([[ 1, 0], [-3, 2]]) numpy.random.random_integersnumpy.random.random_integers(low, high=None, size=None) 返回随机整数，范围区间为[low,high]，包含low和high 参数：low为最小值，high为最大值，size为数组维度大小 high没有填写时，默认生成随机数的范围是[1，low] 1np.random.random_integers(5, size=5) 1array([5, 4, 2, 3, 1]) 生成[0,1)之间的浮点数 numpy.random.random_sample(size=None) numpy.random.random(size=None) numpy.random.ranf(size=None) numpy.random.sample(size=None) 12345678print('-----------random_sample--------------')print(np.random.random_sample(size=(2,2)))print('-----------random--------------')print(np.random.random(size=(2,2)))print('-----------ranf--------------')print(np.random.ranf(size=(2,2)))print('-----------sample--------------')print(np.random.sample(size=(2,2))) 123456789101112-----------random_sample--------------[[ 0.19678647 0.64750281] [ 0.70380805 0.18626702]]-----------random--------------[[ 0.05688147 0.57224742] [ 0.5821726 0.8344959 ]]-----------ranf--------------[[ 0.57307708 0.08199258] [ 0.50676558 0.79959829]]-----------sample--------------[[ 2.25676224e-04 8.76885950e-01] [ 7.52204914e-01 6.43694560e-01]] numpy.random.choice()numpy.random.choice(a, size=None, replace=True, p=None) 从给定的一维数组中生成随机数 参数： a为一维数组类似数据或整数；size为数组维度；p为数组中的数据出现的概率 a为整数时，对应的一维数组为np.arange(a) 1np.random.choice(5, 3) 1array([4, 4, 2]) 123np.random.choice(5, 3, replace=False)# replace为False时，生成的数不能有重复的 1array([0, 3, 1]) 1np.random.choice(4, 4, replace=False) 1array([1, 0, 2, 3]) 1234np.random.choice(4, size=(3, 2))array([[2, 1], [2, 3], [1, 1]]) 12demo_list = ['lenovo', 'sansumg','moto','xiaomi', 'iphone']np.random.choice(demo_list,size=(3,3)) 1234array([['lenovo', 'sansumg', 'lenovo'], ['moto', 'sansumg', 'sansumg'], ['sansumg', 'iphone', 'moto']], dtype='&lt;U7') 123# p是指定每个元素的概率，概率和应为1，且数据个数与a应该相同demo_list = ['lenovo', 'sansumg','moto','xiaomi', 'iphone']np.random.choice(demo_list,size=(3,3), p=[0.1,0.6,0.1,0.1,0.1]) 1234array([['sansumg', 'sansumg', 'iphone'], ['sansumg', 'sansumg', 'xiaomi'], ['sansumg', 'sansumg', 'sansumg']], dtype='&lt;U7') numpy.random.seed() np.random.seed()的作用：使得随机数据可预测。 当我们设置相同的seed，每次生成的随机数相同。如果不设置seed，则每次会生成不同的随机数 1234567for i in range(10): np.random.seed(2) print(np.random.rand(5)) print(np.random.rand(5)) print(np.random.rand(5)) print(np.random.rand(5)) print() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548]]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShuffleNetV2]]></title>
    <url>%2F2019%2F01%2F23%2FShuffleNetV2%2F</url>
    <content type="text"><![CDATA[论文地址 摘要&emsp;&emsp;近年来，神经网络的结构设计极大地被间接度量计算复杂度（如FLOPs）导向，直接度量速度还会被其它因素诸如内存存取消耗和平台特性所影响。因此，我们的工作打算计算目标平台的直接度量，而不仅仅考虑间接度量FLOPs。基于一系列的限制性实验，我们的工作获得了一些有效的网络设计的实用指南。相应地，我们提出了ShuffleNet V2这种新的网络结构。进行了全面的消融实验后，我们证实了在速度和准确率进行权衡的情况下，ShuffleNet V2是最先进的。 1 介绍 &emsp;&emsp;深度神经网络经过最近几年的发展变得更加准确和更加快速。但是在高准确率下计算复杂度这个重要问题被忽略了。实际任务中要求在目标平台（如硬件）和应用场景（如需要低延迟的自动驾驶）这些计算有限制的情况下得到最高的准确率。这激励了一些轻量级网络的研究，并且需要在速度和准确率之间做更好地平衡，此类网络有Xception,MobileNet,MobileNet V2,ShuffleNet和CondenseNet。这些工作中分组卷积和深度卷积有十分重要的作用。&emsp;&emsp;计算复杂度采用最广泛的度量是FLOPs。但FLOPs是一个间接度量。它只是一个近似值，而且和我们关注的直接度量如速度或延迟通常情况下是不等的，这种差异已经被许多工作证实。因此，仅仅使用FLOPs作为复杂度度量是不充分的，并且会导致设计的架构不是最优的。&emsp;&emsp;导致间接度量（FLOPs）和直接度量（速度）的差异主要有两个。首先FLOPs没有顾忌对速度有影响的几个重要因素。一个因素是内存访问消耗，这种消耗在某些操作比如分组卷积占有很大一部分运行时间,这可能是大型设备比如GPU的瓶颈。这个成本在网络架构设计的时候不能被忽略。另一个因素是并行度。在相同的FLOPs下，高并行度的网络比低并行度的网络运行更快。&emsp;&emsp;另一个因素是相同的FLOPs需要的运行时间不同,这取决于平台。比如，张量分解被广泛地用于早期的加速矩阵乘法运算。但是最近的研究发现分解在减少了75%FLOPs的情况下在GPU上的速度更慢。我们调查发现最新的CUDNN对3x3的卷积会进行特殊优化，并不能确定3x3的卷积一定比9个1x1的卷积速度慢。&emsp;&emsp;根据这些观察结果，我们提出了两个应该被并用于有效网络架构设计的原则。第一，使用直接度量代替间接度量；第二，在目标平台上计算相同的度量。&emsp;&emsp;在我们的工作中，我们遵循这两个原则并提出了一个更有效的网络架构。在第二部分，我们首先分析了两个具有代表性的先进网络的运行时间。之后，我们获得了四个有效网络设计的指导方针，这些方针超出了FLOPs的考虑范围，而且与平台无关。我们使用专门优化的代码在两个平台（GPU和ARM）上做了一系列控制实验去证实他们，确信我们的结果是最先进的。&emsp;&emsp;在第三部分，根据指导方针，我们设计了一个新的网络结构。它是ShuffleNet网络的衍生版本，名为ShuffleNet V2。经过第四部分全面的实验后证实ShuffleNet V2在所有的平台上比之前的网络更快更准确。 2 有效网络设计的实际指导方针&emsp;&emsp;我们的研究是在两个广泛采用的硬件上对CNN库进行工业级优化。我们注意到我们的CNN库比大部分开源的CNN库更有效，因此，我们确信我们的观察结果和结论是有力的并且在工业中实践是有意义的。 &emsp;&emsp;其它的设置包括：打开所有的优化项（比如：用于减少小运算带来的计算开支的张量融合）。图片的输入尺寸是$224\times 224$。每个网络进行随机初始并计算100次，采用平均运行时间。&emsp;&emsp;在开始我们的工作前，我们先分析了目前两个最先进的网络ShuffleNet V1和MobiileNet V2的运行时间。它们在ImageNet分类任务中都十分有效和准确。并且它们都被低端设备比如手机广泛应用。虽然我们仅分析这两个网络，但这两个网络代表了现在的趋势。它们的核心是分组卷积和深度卷积，这些操作是目前先进网络的重要组成部分，比如ResNeXt,Xception,MobileNet和CondenseNet。&emsp;&emsp;综合的运行时间被不同的运算分解，如图2，我们注意到FLOPs度量仅仅计算卷积部分的花费。尽管卷积占所有运算的大部分，但是其它的运算包括数据输入输出，数据混洗以及逐元素运算也占据了大量的时间。FLOPs不能够精准地评估运算时间。&emsp;&emsp;基于这个观察结果，我们从不同的方面对运行时间提出了细节的分析，并且获得了几个有效网络架构设计的指导指南。 G1)相同的通道可以最小化内存存取消耗&emsp;&emsp;现在的网络通常采用深度分离卷积，在深度分离卷积中，1x1的卷积占据了绝大部分复杂度。我们开始研究1x1卷积。1x1卷积由两个参数来表示，输入通道数$c_{1}$,输出通道数为$c_{2}$。h和w是特征图的长和宽，1x1卷积的FLOPs是 B=hwc_{1}c_{2}&emsp;&emsp;为了简化计算，我们假定计算设备足够存储全部的特征图和参数，这样的话，内存存储消耗 MAC=hw(c_{1}+c_{2})+c_{1}c_{2}&emsp;&emsp;从均值不等的情况，我们可以得出: MAC\geq 2\sqrt{hwB}+\frac{B}{hw}(1)&emsp;&emsp;从公式（1）可以看出，MAC的下限被FLOPs捆绑，输入通道数等于输出通道数的时候MAC达到最小。&emsp;&emsp;这个结论只是理论上，实际中很多设备的缓存没有假设的那么大，而且现代计算库通常采用复杂的阻塞策略来充分利用缓存机制。因此，真实的MAC值肯能会偏离理论上的值。为了证实我们的结论，我们随后进行了实验，通过重复堆叠10个构建块来构建基准网络，每一个块包括两个卷积层，第一层输入通道为$c_{1}$，输出通道为$c_{2}$，下一层网络与之相反。&emsp;&emsp;表1展示了实验结果，当输入输出通道数比值为1：1时，可以看出MAC值会变得更小并且网络计算速度会更快。 G2)过大的分组卷积会提高MAC&emsp;&emsp;目前分组卷积是很多先进网络的核心部分，它通过将密集卷积的通道分组进行卷积来减少计算复杂度（FLOPs），因此它可以在与传统结构在FLOPs相同的情况下使用更多的通道，进而提升模型的性能。但是，提升的通道数导致了更大的MAC。&emsp;&emsp;从（1）的公式进行推导，FLOPs的值 B=hwc_{1}c_{2}/g&emsp;&emsp;1x1的分组卷积中MAC和FLOPs的关系为： MAC=hw(c_{1}+c_{2})+\frac{c_{1}c_{2}}{g}$$$$=hwc_{1}+\frac{Bg}{c_{1}}+\frac{B}{hw}(2)&emsp;&emsp;g是分组数。从公式中可以看出，在给定输入尺寸$c_{1}\times h\times w$和计算量B，MAC的值与g的值正相关。&emsp;&emsp;为了研究在实践过程中的有效性，我们堆积了10个逐点组卷积来构建基准网络。表2展示了在相同的FLOPs情况下运行速度的差异。从表中可以清晰地看出分组数对运行速度的影响。对比分组数为1和分组数为8的实验结果可以看出，分组数为8的模型运行速度是分组数为1的一倍，在ARM上的数独也慢了30%。&emsp;&emsp;因此，我们建议分组数应该基于目标平台和任务认真选择。简单地增加分组数愚蠢的，因为这在增加准确率的同时也会增加计算量，很可能得不偿失。 G3)分裂网络会减少并行度&emsp;&emsp;在GoogleNet的一系列网络和自动生成网络中，大量采用的了“多径”网络来提高准确率。使用小的操作（分裂网络）来代替一些大网络会带来准确率的提升，但是由于这种操作对大型计算设备如GPU的并行性不是很友好，而且会在内核启动和同步的时候带来额外消耗，因此它会增加计算量。&emsp;&emsp;为了量化分裂网络是如何影响效率的，我们使用不同数量的分类网络制作了一系列网络模块进行实验。每个网络模块包含1-4个1x1的卷积，如何将10个这样的模块堆积在一起组成一个网络，然后它们进行顺序运算或者并行运算。进行的实验效果如表3所示。&emsp;&emsp;表3展示了分裂网络显著地降低了GPU的速度，比如4个分裂网络结构的速度只有1个分类网络结构的1/3。在ARM上的减少相对来说很小。 G4)逐像素操作不可忽视&emsp;&emsp;如图2所示，在轻量级网络中逐像素操作在时间上占据了很大一部分，特别是在GPU上。在我们文章中，逐像素操作包括ReLU，AddTensor，AddBias等等。它们有很小的FLOPs但是在有着很大的MAC。我们将深度卷积也作为逐像素的一员，因为它的MAC与FLOPs的比值很高。&emsp;&emsp;为了验证我们的猜想，我们使用“bottlenecks”单元进行了实验，分别去除ReLU和短路连接，在表4中可以看到实验结果。当两个操作都被去除时，在GPU和ARM上都会得到20%的加速。 结论和讨论&emsp;&emsp;根据上面的指南和研究经验，我们推断一个有效的网络架构需要1）使用平衡的卷积操作（通道相等）；2）关注分组卷积的损失；3）减少分裂的程度；4）减少逐像素操作，这些理想的属性取决于超出理论FLOPs的平台特性（例如内存操作和代码优化）。 3 ShuffleNet V2：一个有效的架构3.1 评价ShuffleNet V1&emsp;&emsp;ShuffleNet是目前先进的网络结构，它被广泛地用于计算能力较低的终端设备比如手机。根据ShuffleNet论文所描述的，目前轻量级网络的主要挑战是在给定计算量的前提下特征通道数量的限制。为了在不提高FLOPs的情况下提高通道数，他们采用了逐点群卷积和bottleneck型的结构。为了提高不同组之间的信息交流，他们使用了通道混洗操作，同时准确率得到提升。根据第二部分的讨论，逐点群卷积和bottleneck结构都会提高MAC(G1和G2)，这个损失是不能忽略的，并且，使用太多的分组也违背了G3，在捷径连接中的逐像素“Add”操作也违背了G4。因此，为了建立一个高效的模型，关键问题是保持与密集卷积相同的通道数，并且不能有太多的分组。 3.2 通道分离和ShuffleNet V2 &emsp;&emsp;根据上面的目的，我们介绍了一种简单的操作名为通道分离（channel split）。在图三(c)中可以看到。在每个单元的开始出，输入通道数c被分成了两个独立的分支c和c’。遵循G3的指导，一个分支独自保留。另一个分支由三个卷积组成并且输入输出通道数遵循G1的原则保持一致。两个1x1卷积部分遵循G2没有进行分组卷积（因为channel split操作分成了两个组）。&emsp;&emsp;卷积之后两个分支被串联（concatnated)，因此通道数保持一致。与ShuffleNet相同的通道混洗操作放到了两个分支串联之后，被用来进行信息交流。&emsp;&emsp;在通道混洗之后，就会开始下个单元。可以注意到ShuffleNet V1中的“Add”操作被取消了。逐像素操作如ReLU和设定卷积只存在一个分支上，并且三个连续的逐像素操作cancat,channel shuffle和channel split被合并成一个逐像素操作。根据G4这种改变是有利的。对于空间下采样，如图3（d），移除了通道分离操作，之后的通道会翻倍。&emsp;&emsp;遵循上面提出的4个指导方针，我们提出了图3（c）（d）这种模块，将其命名为ShuffleNet V2。使用上面的模块进行堆积就会建好网络。为了便利，我们将c’设置为c的一半。整体的网络结构与ShuffleNet v1类似，见表5。唯一的不同之处是：ShuffleNet v1缺少了global averaged pooling层。与ShuffleNet v1相似，我们设置了不同的网络通道数比例来产生不同的网络来适应不同的复杂度。 3.3 网络准确性性分析&emsp;&emsp;ShuffleNet V2网络不仅高效，而且准确，主要两个原因，每个构建模块组成的高效率能够使用更多的特征通道和更大的网络容量。第二个原因是每个模块都会有三分之一的特征通道被直接通过模块进入下一个模块。这可以理解为一种特征重用，在DenseNet和CondenseNet中有相似的部分。在DenseNet中，为了分析特征重用模式，绘制了层间权重的l1范数，如图4（a）所示。很明显，相邻层之间的连接比其他层更强。这意味着所有层之间的密集连接可能引入冗余。最近的CondenseNet也支持这一观点。在ShuffleNet V2中，很容易证明第i和第（i + j）个构建块之间的“直接连接”通道的数量是$r^{j}c$，其中r =（1-c’）/ c。换句话说，特征重用量随着两个块之间的距离呈指数衰减。在远程块之间，特征重用变得更弱。图4（b）绘制了与（a）中类似的可视化，其中r = 0.5。注意，（b）中的模式类似于（a）。因此，ShuffleNet V2通过设计实现了这种特征重用模式，它与DenseNet有着高精度特征重用的相似性，但是它的效率更高，在表8中将证实。 4 实验&emsp;&emsp;我们的消融实验在ImageNet2012的分类数据集上进行，和之前轻量级网络的实验设置相同，所有的网络在四个复杂度上进行比较，分别为40、140、300和500MFLOPs。这些复杂度在移动场景中具有典型性，其它的超参数和协议与ShuffleNet v1相同。我们比较了4种网络： ShuffleNet v1：分组设置为3 MobileNet v2：我们将论文中的准确率与我们复现的准确率都列出来，有一些结果论文中并没有 Xception：原始的Xception非常大，我们采用最近的一个对它进行修改后的衍生版本 DenseNet：原始的网络不适合进行对比实验，我们将表5中的2-4步替换为DenseNet网络的模块进行对比实验，通过调整通道数来控制网络复杂度。 &emsp;&emsp;表8显示了所有结果。我们对结果从不同方面进行分析。&emsp;&emsp;同FLOPs比较速度 &emsp;&emsp;推理速度/(FLOPs/Accuracy)IGV2、IGV3使用通道多，速度慢。 &emsp;&emsp;与其它网络的兼容性 &emsp;&emsp;构成大网络后效果 &emsp;&emsp;目标检测 大的感受野可以增加目标检测的效果（Xception），我们在增加了一个3x3卷积在每个模块的1x1卷积之前，构成ShuffleNet v2*。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>轻量级网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShuffleNet]]></title>
    <url>%2F2019%2F01%2F23%2FShuffleNet%2F</url>
    <content type="text"><![CDATA[[论文地址] 摘要&emsp;&emsp;我们介绍一种被设计用于计算能力有限的移动装置的卷积网络ShuffleNet，新的结构使用逐点群卷积和通道混洗方式，在保持准确率的情况下极大地减少运算量。在一个基于ARM的移动装置中，ShuffleNet在和AlexNet保持相同的准确率的情况下速度提升了13倍。 1 介绍&emsp;&emsp;目前更大更深的网络是主流趋势，主要是为了解决主流视觉识别任务。准确率最高的网络有上百层网络和上千层通道，需要的上百亿的FLOPs(每秒浮点数运算）。这篇报告与之完全对立，在保持最高的准确率的同时把计算量控制在10~100个百万FLOPs内，专注于公共移动平台，如无人机，机器人和智能手机。之前的工作主要致力于剪枝、压缩和使用小存储量代替基础网络结构。我们致力于提出一种新的适用于计算量有限制的基础网络结构。&emsp;&emsp;我们注意到现在最先进的网络如Xception和ResNeXt在小网络的作用及其有限，因为密集的1X1卷积.因此我们提出逐点群卷积来降低1x1卷积的计算复杂度，群卷积会带来一些负面作用，我们使用通道混洗来解决这个问题。基于这两种方法，我们建立了一种高效结构，命名为ShuffleNet。与流行的结构相比，我们的结构可以允许更多的特征图通道在给定计算量的前提下，能够编码更多的信息，这对小网络的表现十分重要。 2 相关工作2.1 高效模型的设计&emsp;&emsp;过去几年深度神经网络在计算机视觉任务上取得了成功，其中模型设计起了很大的作用。在可嵌入设备中运行更大更深的网络的需求不断增加，这激励了高效模型设计的研究。例如，GoogleNet与简单地堆叠卷积层的网络相比，增加了网络的深度并且复杂度更低。SqueezeNet在控制准确率的情况下显著地减少了计算量和参数。ResNet使用有效的bottleneck结构来提升性能。SENet介绍了一种能够花费较小计算量来提升性能的结构单元。 2.2 组卷积&emsp;&emsp;组卷积的概念是AlexNet中提出来的，当时是为了两块GPU进行运算，并且在ResNeXt中证明了其有效性。深度分离卷积在Xception中提出并且分离卷积在Inception系列中得到推广。MobileNet使用深度分离卷积并且在轻量级网络中获得了最先进的结果。我们的工作是推广群卷积和一种新形式的深度分离卷积。 2.3 通道混洗&emsp;&emsp;在我们的认知中，通道混洗在高效网络模型设计中很少被提及。虽然CNNC库cuda-convnet支持随机通道卷积，这个操作相当于在组卷积后进行随机通道交换。这种“随机混洗”有不同的用途但是之后很少有人探索。最近有个two-stage卷积的工作采用了这个方法但是并没有深入研究通道混洗本身以及它在小模型设计上的作用. 2.4 模型加速&emsp;&emsp;这个部分致力于加速推理同时保持预训练模型的准确率。对网络的连接和通道进行剪枝来减少网络在预训练模型的冗余连接以保模型性能。在文献中，量化和因式分解备用来减少冗余计算来加速推理。不修改参数，FFT和其它方法使用卷积方法工具来减少训练的时间消耗。把大网络的知识提炼到小网络，使训练小网络更加简单。 3 方法3.1 对分组卷积的通道混洗&emsp;&emsp;现在的卷积神经网络通常由相同结构组成的重复模块构成。1x1的卷积没有全部采用的原因是1x1卷积需要相当大的复杂度.在小网络中，昂贵的逐点卷积会因复杂度限制而控制通道数量，这可能显著地减少准确率.&emsp;&emsp;解决这个问题的直接方案是通道稀疏连接，比如包括1x1卷积的分组卷积。确保每个输入通道组上进行相应的卷积，组卷积就会显著地降低计算成本。但是这会带来新的问题：一些通道的输出仅仅来源于输入通道的一小部分。图1（a）说明了这种情况。很明显地看出，每个输出组只与它的输入组之间有联系。这个特性阻隔了通道组和弱表示的信息流动。&emsp;&emsp;如果我们允许分组卷积可以从不同的组中获得输入数据，(如Figure1(b)),输入通道和输出通道就会全部建立联系。对于上一层分组卷积产生的特征图，我们可以把每个组的通道分离成更小的组，然后将这些组随机排序作为下一层网络每个组的输入。这个操作可以使用通道卷积方便快捷地实现（如Figure1（c））：计算拥有$g*n$个通道数g个组的卷积层；我们需要先将数据改变形状变为$(g,n)$,然后转换和扁平化作为下一层的输入。在其中我们注意到这个操作在经过两层不同分组的卷积后依然有效。更重要的是，通道混洗过程是十分微小的，这意味着它能够嵌入到端对端的网络训练中。&emsp;&emsp;通道混洗操作使得使用大量分组卷积层的有效网络变得可能.在下一个部分我们将介绍一个使用分组卷积和通道混洗结构的有效的网络单元。 3.2 ShuffleNet单元&emsp;&emsp;基于通道混洗操作的优点，我们提出了专门为小网络设计的新结构ShuffleNet单元。我们的设计基于ResNet的bottleneck模块（如Figure2（a））。这是一个残差模块。在他的残差分支中，我们在bottleneck模块的特征图提取模块采用了适合运算的3x3的深度卷积。之后，我们将第一个1x1卷积替代为逐点群卷积，之后进行通道混洗，这样来组成ShuffleNet单元，如Figure2（b）。第二个逐点群卷积的作用是将通道恢复到与捷径路线相同的尺寸。简单来说，我们在第二个逐点群卷积后并没有采用通道混洗，因为采用与否对结果没有影响。在ShuffleNet单元哪个位置设置步长的问题上，我们简单地进行了两个修改（如Figure2（c））：在捷径路线上添加3x3的平均值池化层；使用通道级联（channel concatenation)代替元素相加，这样可以在很少的额外计算下扩大通道尺寸。&emsp;&emsp;与ResNet和RexNeXt相比较，我们的模型有更少的计算量。输入为$chw$bottleneck通道数为m,ResNet单元要求$hw(2cm+9m^2)$FLOPs，ResNeXt单元要求$hw(2cm+9m^2/g)$FLOPs。ShuffleNet单元需要$hw(2cm/g+9m)$FLOPs，g是卷积的分组数。换句话说，在相同的计算量预算下，ShuffleNet可以使用更广泛的特征图。我们发现这对小网络是十分重要的，因为小网络在获取信息的过程中通道数量是不足的。&emsp;&emsp;另外，ShuffleNet深度卷积仅应用于bottleneck特征图。虽然深度卷积在理论上有很少的计算量，但我们发现将它移植到低功耗的移动设备上是十分困难的，与其他密集网络相比，ShuffleNet网络可能会在计算与内存存取上存在不平衡。 3.3 网络结构&emsp;&emsp;基于ShuffleNet单元，我们建立了如Table 1的ShuffleNet网络结构。提出的网络主要是由三个阶段聚集组成的ShuffleNet单元组成的。每个阶段首先建立的模块采用的步长为2.其它的超参数设置相同，并且下一个阶段的输出通道数翻倍。我们将bottleneck的通道数设置为输出通道的1/4.我们打算提供一种尽可能简单的基本设计，尽管我们发现进一步的超参数设置可能会带来更好的结果。&emsp;&emsp;在ShuffleNet单元中，分组数g控制着逐点卷积的稀疏性。Table 1展示了不同组数的效果，我们采用的输出通道数尽可能使复杂度不变。效果十分明显，在相同的复杂度下大的分组导致更多的输出通道（这也意味着更多的卷积核），这意味着在输入通道有限的情况下大分组可以编码更多的信息。&emsp;&emsp;Table 1是网络的完全体，之后的ShuffleNet $s*$意味着网络的复杂度大致是原网络的$s^2$. 4 实验]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>轻量级网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MobileNetV2 倒置残差和线性瓶颈]]></title>
    <url>%2F2019%2F01%2F23%2FMoblieNetV2%2F</url>
    <content type="text"><![CDATA[参考博客论文地址 摘要&emsp;&emsp;在本文中，我们描述了一种新的移动网络结构MobileNetV2，它提高了移动网络在多类型任务和基准以及不同网络尺寸范围的最佳性能。我们还介绍了一种有效地使用轻量级网络进行目标检测的新颖架构SSDLite。并且我们将Deeplabv3进行修剪后构建出一种用于移动语义分割的模型，称为Mobile Deeplabv3。&emsp;&emsp;MobileNetV2基于倒置残差结构，并且在窄boottleneck层中有快捷连接。中间的扩大层使用轻量级的深度卷积来过滤特征作为非线性的来源。另外，我们发现在窄层中去除非线性来保持表现能力是很重要的，我们证明了这可以提高性能并且直观地启发了我们网络的设计。&emsp;&emsp;最后，我们的方法允许输入/输出域与转换的表达性分离，这为进一步分析提供了方便的框架。我们测量我们在ImageNet分类，COCO物体检测，VOC图像分割上的表现。我们评估准确性与乘法加法（MAdd）测量的操作次数，实际延迟和参数数量之间的权衡。 1 介绍&emsp;&emsp;神经网络在机器智能领域有革命性地作用，比如在图像识别任务中超过了人类的识别准确率。然而，提高准确率的同时带来了新的代价：先进的网络需要的高计算能力超越了许多手机和嵌入式应用计算能力。&emsp;&emsp;本文介绍了一种新的为移动和资源受限环境特殊定制的神经网络结构。我们的网络在保持相同准确率的情况下通过减少计算量和内存需求，推动了移动定制计算机视觉模型的水平。&emsp;&emsp;我们主要贡献是一种新的层模块：具有线性瓶颈的倒置残差。这个模块采用了一种低维的压缩表示作为输入，首先扩展成高维然后使用轻量级深度卷积过滤。随后使用线性卷积将特征投影回低维表示。官方实现TensorFlow-Slim提供一部分操作。&emsp;&emsp;该模块可以在任何现代框架中使用标准操作有效地实现，并允许我们的模型使用标准基准测试在多个性能点上击败最新技术。此外，这种卷积模块特别适用于移动设计，因为它可以通过永远不会完全实现大型中间张量来显着减少推理期间所需的内存占用。这减少了许多嵌入式硬件设计中对主存储器访问的需求，这些设计提供了少量非常快速的软件控制的高速缓冲存储器。 2 相关工作&emsp;&emsp;在最近几年，调整深度神经网络的架构以在准确率和性能之间有一个最佳平衡成为一个积极研究的领域。早期的网络如AlexNet,VGGNet,GoogLeNet以及ResNet，这些网络的设计都进行了大量的手工体系结构搜索和训练算法改进。最近在网络架构探索上有了很多进展，比如超参数还有各种网络修剪方法以及连通性学习。大量的工作也致力于内部卷积模块的连接架构的改变，比如ShuffleNet[20]或引入了稀疏性[21]和其它[22]。&emsp;&emsp;最近，[23, 24, 25, 26]引入了架构探索的新方向，将遗传算法和强化学习加入了其中。然而一个缺点是得到的网络最终会十分复杂。本文的目的是找到然后是神经网络更好地运作并用它指导最简单的网络设计。我们的方法应该被视为[23]描述方法的一种互补和相近的工作。在这种情况下，我们的方法类似于[20,22]所采用的方法并允许进一步改善性能，同时提供内部操作的一部分。我们的网络设计基于MobileNetV1。保留了它的简洁性而且不要求任何特殊操作就能显著提升准确率，实现了移动应用的多图像分类和检测任务的最新技术。 3 预备、讨论和直觉3.1 深度可分离卷积&emsp;&emsp;深度可分离卷积是现在很多高效神经网络模块的关键部分，并且我们也将其应用到我们的网络中。基础思想是使用分解的版本代替全卷积层，将全卷积层分为深度卷积和点卷积两个部分。第一次深度卷积是使用单个卷积滤波器在每个输入通道上进行轻量级滤波。第二次点卷积使用1x1的卷积主要负责通过计算输入通道的线性组合来建立新的特征。&emsp;&emsp;标准卷积在输入通道为$d_{i}$输出通道为$d_{j}$，卷积和大小为$k\times k$的情况下计算量为$h\times w\times d_{i}\times d_{j}\times k^2$。深度可分离卷积的计算量为 h*w*d_{i}*(k^2+d_{j})(1)，实验证实深度可分离卷积在性能上与常规卷积几乎相同，但计算量大致变为原来的$1/k^2$。我们使用的k为3。 3.2 线性瓶颈&emsp;&emsp;思考一个深度神经网络由n层组成$L_{i}$，每个$L_{i}$有h_{i}*w_{i}*d_{i}激活张量。这节我们讨论这些张量的基础特性，我们将这些张量视为$h_{i}*w_{i}$个像素点的$d_{i}$维的容器。非正式地，对于一个真实图片的输入集合，我们说激活层集合组成了“多方面兴趣”。长期以来，人们一直以为神经网络的多方面兴趣可以嵌入到低维的子空间中。换句话说，当我们查看深度卷积层的所有单个d通道像素时，在这些值中编码的信息实际上位于某些流形中，而这些流形又可嵌入到低维子空间中。&emsp;&emsp;乍一看，这些事实可以简单地通过减少层的尺寸来捕获和利用从而减少操作空间的尺寸。这在MobileNetV1中成功地通过宽度乘数有效地平衡计算量和准确率。遵循这种直觉，这种宽度乘数方法允许人们减少激活空间的尺寸，直到感兴趣的流体经过整个空间。然而，当我们回想深度卷积网络实际上在每次坐标变换时都有非线性时比如ReLU，这种直觉会崩溃。例如，应用于1D空间中的线的ReLU产生“射线”，与在Rn空间中一样，它通常产生具有n关节的分段线性曲线。&emsp;&emsp;很容易看出，在通常情况下，ReLU转换层的结果有非零的体积S，通过对输入进行线性转换B获得测绘内部S的点，这意味部分对应于全维输出的输入空间受限于线性变换。换句话说，深度网络仅仅在非零部分具有线性分类器的能力。&emsp;&emsp;在另一方面当ReLU合并通道时，必然会损失通道信息。但是我们如果有很多通道，并且激活流形中有一个机构，那么信息可能会保留在其它通道中。在附录中，我们展示了如果输入流形能够被嵌入到激活空间的显著低维子空间中，之后ReLU变换会保留信息同时在可表达功能集中引入所需的复杂性。&emsp;&emsp;总而言之，我们强调了两个属性，这两个属性表明感兴趣的流形应位于高纬度激活空间的低纬度子空间： 1.如果感兴趣的流形在ReLU变换后保持了非零量，与线性变换相同。 2.ReLU在保留输入流形的全部信息是十分重要的，但是仅在输入流形位于输入空间的低维子空间时有效。 &emsp;&emsp;这两个见解为我们提供了优化存在的神经网络结构的经验暗示：假如感兴趣的流形是低维的，我们能够在卷积模块中插入线性瓶颈来捕获它。通过实验证明，线性模块是十分重要的，因为它阻止非线性破坏太多信息。在第六节中，我们凭经验证明，在瓶颈中使用非线性层确实会使性能受到几个百分点的影响，从而进一步验证了我们的假设3。 我们注意到在[29]中报告了有助于非线性的类似报告，其中从传统残差块的输入中去除了非线性并且导致CIFAR数据集的性能提高。&emsp;&emsp;对于本文的其余部分，我们将利用瓶颈卷积。 我们将输入瓶颈尺寸与内部尺寸之间的比率称为膨胀比。 3.3 残差倒置&emsp;&emsp;瓶颈网络和残差块十分相似，其中每个块包含一个输入，之后是几个瓶颈，然后是扩展。然而，受到瓶颈模块实际上包含所有必要信息的直观启发，虽然扩展层仅仅作为伴随张量的非线性变换的实现细节，但我们在瓶颈之间直接使用快捷方式。&emsp;&emsp;图3提供了设计差异的示意图。 插入快捷方式的动机类似于经典残差连接的动机：我们希望提高梯度在乘数层上传播的能力。 然而，倒置设计的内存效率要高得多（详见第5节），并且在我们的实验中效果稍好一些。&emsp;&emsp;瓶颈卷积的运行时间和参数数量。基本结构如表一所示。对于大型为$h\times w$的块，扩展因子为t，内核大小为k，输入通道为$d^{‘}$输出通道为$d^{‘’}$，矩阵乘法计算总量为 h*w*d^{'}*t(d^{'}+k^{2}+d^{''})与（1）相比多了额外的项,因为我们确实有一个额外的1×1卷积，但是我们网络的性质允许我们使用更小的输入和输出维度。 在表3中，我们比较了MobileNetV1，MobileNetV2和ShuffleNet之间每个分辨率所需的大小。 3.4 信息流动的说明&emsp;&emsp;我们的架构有个很有趣的特性：它能够对构建块（瓶颈块）的输入输出域进行自然分离，这是一种将输入转换为输出的非线性函数。前者可以看出每层网络的容量，后者可以看做是表现能力。这与传统的卷积模块存在差异，包括常规网络和分离网络，它们的容量和表现力混在一起并且是输出层深度的函数。&emsp;&emsp;特别是，在我们的例子中，当内层深度为0时，由于快捷连接，底层卷积是身份函数。当膨胀比小于1时，这是一个经典的残余卷积块[8,30]。但是，出于我们的目的，我们表明膨胀率大于1是最有用的。&emsp;&emsp;这种解释使我们能够将网络的表现力与其容量分开研究，并且我们认为有必要进一步探索这种分离，以便更好地理解网络属性。 4 网络结构&emsp;&emsp;现在描述我们的网络细节。如前面所述的基础模块是带有残差模块的深度可分离卷积。模块细节在表一。MobileNetV2的结构包括32层滤波器，如表二所示结构，有19层residual bottleneck(17?)。我们使用ReLU6做非线性计算，因为它在低精度运算上有很好的鲁棒性。我们使用3x3的卷积核，并且使用dropout和batch normalization。&emsp;&emsp;除第一层外，我们在整个网络中使用恒定的扩展速率。在我们的实验中，我们发现5到10之间的扩展速率导致几乎相同的性能曲线，较小的网络通过略小的扩展速率获得更好的结果，而较大的网络具有稍微更好的性能和更大的扩展速率。&emsp;&emsp;对于我们所有的主要实验，我们使用应用于输入张量大小的扩展因子6。例如，对于采用64通道输入张量并产生具有128个通道的张量的瓶颈层，中间扩展层则为64·6 = 384个通道。&emsp;&emsp;平衡超参数：我们通过使用输入图像分辨率和宽度乘数作为可调超参数来定制我们的架构到不同的性能点，可以根据所需的精度/性能权衡进行调整。 我们的主要网络（宽度乘数1,224×224）具有3亿乘法的计算成本，并使用340万个参数。我们探索性能权衡，输入分辨率从96到224，宽度乘数从0.35到1.4。网络计算成本范围从7M MAdds到585M MAdds，而模型大小在1.7M和6.9M参数之间变化。&emsp;&emsp;一个小的实现差异，[27]是对于小于1的乘数，我们将宽度乘数应用于除最后一个卷积层之外的所有层。这可以提高较小网络的性能。 5 实验记录5.1 存取效率推断&emsp;&emsp;内存的大小由瓶颈张量的大小决定，而不是瓶颈内部张量的大小决定的（并且更大）。&emsp;&emsp;我们的瓶颈残差模块先扩展后压缩。 6 实验6.1 ImageNet分类&emsp;&emsp;训练设置：我们使用TensorFlow训练我们的模型[31]。 我们使用标准的RMSPropOptimizer，将衰减和动量设置为0.9。我们在每一层之后使用批量标准化，标准重量衰减设置为0.00004。在MobileNetV1 [27]设置之后，我们使用0.045的初始学习率和每个时期0.98的学习率衰减率。我们使用16个GPU异步工作器，批量大小为96。 &emsp;&emsp;结果:我们将我们的网络与MobileNetV1，ShuffleNet和NASNet-A模型进行比较。表4显示了一些选定模型的统计数据，其完整性能图如图5所示。 6.2 目标检测&emsp;&emsp;我们评估和比较MobileNetV1和MobileNetV2在SSD在COCO数据集上中特征提取的性能，我们也比较了YOLOv2和单个SSD作为基准。&emsp;&emsp;SSDLite：我们将SSD的预测层的常规卷积全部替换为深度分离卷积，这种模型适用于移动设备，称为SSDlite，SSDlite显著地减少了计算量和参数，如表5所示。表6显示了所有的计算结果。 6.3 语义分割6.4 强化学习7 讨论和未来工作]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>轻量级网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习笔记]]></title>
    <url>%2F2019%2F01%2F23%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[培养专注的习惯，学会独立思考 1 学习AI需要哪些技能 1.编程基础 熟练使用linux，git，vim等环境和工具。 熟练掌握 C/C++、Python等编程语言。 熟练掌握cmake，g++等编译工具。 2.算法基础 熟悉传统图像算法，机器学习算法。 熟练跟踪并阅读行业前沿研究，复现结果。 系统性熟悉深度学习理论。 3.框架基础 熟练掌握 Caffe、TensorFlow、pytorch等以及不断新出的开源平台。 4.其它基础 掌握爬虫等前后端的基础知识。 了解并熟悉Cuda等GPU编程技术，了解一些移动端的硬件知识。 了解并熟悉 Android、iOS 等移动端的基础知识，在项目中可能会需要使用。 2 吴恩达深度学习课后作业吴恩达深度学习视频作业参考 2.1 神经网络和深度学习2.1.1 logistic回归作业代码 2.1.2 浅层神经网络作业代码 2.1.3 深层神经网络作业代码 2.2 改善深层神经网络2.2.1 深度学习的实用层面3 cs231n课程笔记3.1 图像处理的一些简单方法12345678910from PIL import Imagefrom PIL import ImageEnhanceimport matplotlib.pyplot as plt# 原始图像image = Image.open('match_learning/picture/1.jpg') # 打开图片# image.show()plt.figure("origan_image")plt.imshow(image)plt.show() 123456789# 亮度增强enh_bri = ImageEnhance.Brightness(image)brightness = 1.5image_brightened = enh_bri.enhance(brightness)# image_brightened.show()plt.figure("brightened")plt.imshow(image_brightened)plt.show()image_brightened.save('match_learning/picture/image_brightened.jpg') 123456789# 色度增强enh_col = ImageEnhance.Color(image)color = 1.5image_colored = enh_col.enhance(color)# image_colored.show()plt.figure("colored")plt.imshow(image_colored)plt.show()image_colored.save('match_learning/picture/image_colored.jpg') 123456789# 对比度增强enh_con = ImageEnhance.Contrast(image)contrast = 1.5image_contrasted = enh_con.enhance(contrast)# image_contrasted.show()plt.figure("contrast")plt.imshow(image_contrasted)plt.show()image_contrasted.save('match_learning/picture/image_contrasted.jpg') 123456789# 锐度增强enh_sha = ImageEnhance.Sharpness(image)sharpness = 1.5image_sharped = enh_sha.enhance(sharpness)# image_sharped.show()plt.figure("sharpness")plt.imshow(image_sharped)plt.show()image_sharped.save('match_learning/picture/image_sharped.jpg') 3.2 python学习笔记]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>深度学习</tag>
        <tag>笔记</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.博客搭建参考next主题使用教程多终端同步教程主题美化科学上网 快速开始创建一个新的文章1hexo new "My New Post" More info: Writing 运行服务1hexo server More info: Server 生成静态文件1hexo generate More info: Generating 部署到远程站点1hexo deploy 发布文章1hexo d --g More info: Deployment 添加图片在目标的.comfig.yml文件的38行修改数据，可以在新建博客的同时新建一个资源文件夹来放置图片，博客引用时直接使用![picture](picture_name)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
