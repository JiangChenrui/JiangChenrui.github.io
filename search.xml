<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深度学习目标检测方法汇总]]></title>
    <url>%2F2019%2F06%2F26%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[目标检测简介&emsp;&emsp;目标检测是计算机视觉的一个重要研究方向，是指从一个场景（或图片）中找到感兴趣的目标。任务大致分为三个流程： 从场景中提取候选区 从候选区提取特征 识别候选区的类别并对有效的候选框进行位置精修 &emsp;&emsp;目标检测在生活的各个领域都有了广泛的应用，它是将图像或视频中的目标与不感兴趣的部分区分开，判断是否存在目标，若存在目标则确定目标的位置。近年来，随着互联网技术、人工智能计算和智能硬件的迅猛发展，人类生活中存在着大量的图像和视频数据，这使得计算机视觉的研究也越来越火热。目标检测技术作为计算机视觉领域的一个重要组成部分，也受到了很大程度上的关注。目前在实际生活中的应用也十分广泛，包括目标跟踪，视频监控，信息安全，自动驾驶，图像检索，医学图像分析，网络数据挖掘，无人机导航，遥感信息分析，国防系统，以及机器人环境感知等。&emsp;&emsp;目标检测方法主要分为两大类： 基于传统图像处理和机器学习算法的目标检测方法 基于深度学习的目标检测方法 &emsp;&emsp;传统目标检测方法主要分为六个步骤，包括图像预处理，窗口滑动，特征提取，选择以及分类，和后处理这六个步骤。每个步骤所做的工作分别是：a)图像预处理是对检测图像进行图像的去噪声和增强，以及色彩转换等操作；b)窗口滑动是指在待测图像中滑动一个大小相同的窗口，将窗口中的子图像提取出来做候选区域；c)特征提取就是对候选区域使用特定的算法进行处理；d)特征选择即从上一步提取的特征向量中挑选出具有代表性的特征，降低特征的维数；e)特征分类就是利用特定的分类器对特征进行分类，判定候选区是否包含了目标及其类别；f)后处理是指合并判断为同一类别的相交候选区，计算出每个目标的边界框。&emsp;&emsp;传统目标检测方法的检测重点是在特征提取（如何提高特征的表达能力和抗形变能力）和特征分类（如何提高分类器的准确度和速度上）。由此，研究人员提出了多种形式的特征和分类器，其中，代表性的特征有代表性的特征有SIFT(scale-invariant feature transform)、Hear、HOG(histogram of oriented gradient)、Strip等；代表性的分类器有AdaBoost、SVM(support vector machine)、DPM(deformable parts model)、RF(random forest)等。&emsp;&emsp;但是，传统的目标检测方法的准确度并不能达到实际需求，其根本原因有两个，一个是使用滑动窗口的策略进行区域选择时针对性不强，提高了时间复杂度和窗口冗余，另一个是使用设计的特征。设计的特征存在以下三个缺点：a)设计的特征为低层特征，对目标的表达能力不足；b)设计的特征可分性差，导致分类的错误率较高；c)设计的特征具有针对性，很难选择单一特征应用于多目标检测，例如：Hear特征用于人脸检测，HOG特征用于行人检测，Stip特征用于车辆检测。&emsp;&emsp;随着计算机性能的不断提高，曾经难以实现的深度学习算法变得切实可行，目标检测开始进入深度学习时代。深度学习提取的特征为高层特征，相比于传统的目标检测方法的设计特征，学习的特征更加丰富，表达能力更强。而且深度学习将特征提取，特征选择以及特征分类融合到一个模型中，通过端对端的训练，从整体上进行功能优化，增加了特征的可分性。基于深度学习的目标检测算法大致可以分为三类：a)基于区域建议的目标检测算法：如R-CNN，Fast-RCNN，Faster-RCNN；b)基于回归的目标检测算法：如YOLO，SSD；c)基于搜索的目标检测算法，如基于视觉注意的AttentionNet，基于强化学习的算法。 1 基于区域提名的深度学习目标检测算法&emsp;&emsp;卷积神经网络（CNN）是区域提议（Region Propoal）算法的核心组成部分，卷积神经网络最早是有Yann LeCun教授提出来的，早期的卷积神经网络是用作分类器使用的，主要用于图像识别。卷积神经网络有三个结构上的特性：局部连接、权重共享以及空间和时间上的采样。这些特性使得卷积神经网络具有一定程度上的平移、缩放和扭曲不变性。在2006年Hinton提出使用深度神经网络从大量的数据中自动学习高层特征。区域建议在此基础上解决了传统目标检测方法存在的两个问题。比较常用的区域建议方法有Selective search和Edge boxes。此后，CNN网络迅速发展，微软最新的ResNet和谷歌的Inception V4模型的Top-5 error降到了4%以内，所以目标检测得到候选区域后使用CNN对其进行图像分类的准确率和检测速度上都有提高。这类算法的主要步骤是： 首先使用选择性搜索算法（Selective Serch）、Bing、EdgeBoxes这些目标候选区域生成算法生成一系列候选目标区域； 然后通过深度神经网络提取目标候选区域的特征； 最后用这些特征进行分类，以及目标真实边界的回归。 1.1 R-CNN&emsp;&emsp;R-CNN算法可以说是利用深度学习进行目标检测的开山之作，将深度学习引入了目标检测领域，一举将PASCAL VOC上的检测率从35.1%提升到53.7%。针对传统目标检测方法存在的两个问题，R-CNN都有了很好的解决方法：预先提前一系列可能是物体的候选区域，之后仅在这些候选区域上提取特征，进行判断，从而解决了传统目标检测方法利用滑动窗口依次判断所有可能的区域造成时间复杂度太高和窗口冗余的问题；训练深度网络来进行特征提取替代人工设定特征，解决了人工设定特征的三个缺点。&emsp;&emsp;R-CNN的实现步骤主要有4个： a)首先用选择性搜索算法（selective Search）提取1k-2k个候选区域； b)使用深度卷积神经网络提取每一个候选区的深度特征； c)训练SVM分类器来对这些特征进行分类； d)最后通过边界回归算法程序定位目标边界框。 &emsp;&emsp;但是，由于在特征提取后进行分类的过程中有一个全连接层的操作，这一个操作要求提取特征的图片需要相同尺度的大小，提取的不合适的特征图片需要进行裁切（Crop）或者变形缩放（Warp），这在一定程度上造成图像畸形，影响最终结果。随后He等人提出SPP-NET缩放很好的解决了这一问题。 1.2 SPP-NET&emsp;&emsp;R-CNN存在的问题在SPP-NET解决主要在于SPP网络的提出，这一网络解决了R-CNN这一网络要求提取特征要求相同尺度的大小这一问题。下面是R-CNN和SPP-NET网络结构的对比。 &emsp;&emsp;R-CNN现在提取图片特征后先进行卷积后再进行全连接层的训练，而SPP-NET的网络在进行卷积之后再进行SPP操作，这一操作可以让网络输入任何大小的图片，都会生成固定大小的输出，整体的结构除了这一点以外和之前的R-CNN没有什么不同，因此在其它方面，SPP-NET存在和R-CNN一样的问题。 1.3 Fast RCNN&emsp;&emsp;在2015年，继提出R-CNN算法后，Ross Girshick提出了Faster RCNN，流程更为紧凑，大幅提升了目标检测的速度，同样使用最大规模的网络，Fast R-CNN和R-CNN相比，训练时间从84小时减少为9.5小时，测试时间从47秒减少为0.32秒。在PASCAL VOC 2007上的准确率相差无几，约在66%~67%之间。&emsp;&emsp;Fast RCNN主要解决了R-CNN的三个问题： 测试速度慢RCNN一张图片内候选框之间大量重叠，提取特征操作冗余。Fast RCNN将整张图像归一化后直接送入深度网络，在邻接时，才加入候选框信息，在末尾的少数几层处理每个候选框。 训练速度慢原因同上在训练时，Fast RCNN先将一张图像送入网络，紧接着送入从这幅图像上提取出的候选区域。这些候选区域的前几层特征不需要再重复计算。 训练所需空间大RCNN中独立的分类器和回归器需要大量特征作为训练样本。 Fast RCNN把类别判断和位置精确统一用深度网络实现，不再需要额外存储。 &emsp;&emsp;其中，Fast RCNN最大的贡献是全连接层的提速。&emsp;&emsp;分类和位置调整都是通过全连接层（fc）实现的，设前一级数据为x后一级数据为y，全连接层参数为w，尺寸为$uv$。一次前向传播（forward）即为：y = Wx 计算复杂度为$uv$。 将W进行SVD分解，并用前t个特征值近似W=U\Sigma V^T\approx U(:,1:t)\cdot \Sigma (1:t,1:t)\cdot V(:,1:t)^T 原来的前向传播分解为两步：y = Wx = U\cdot (\Sigma \cdot V^T)\cdot x = U\cdot z 计算复杂度变为$u\times t+v\times t$。 在实现时，相当于把一个全连接层拆分为两个，中间以一个低维数据相连。 其实验结果为： * 网络末端同步训练的分类和位置调整，提升准确度； * 使用多尺度的图像金字塔，性能几乎没有提高； * 倍增训练数据，能够有2%~3%的准确度提升； * 网络直接输出各类概率（softmax），比SVM分类器性能略好； * 更多候选窗不能提升性能。 1.4 Faster R-CNN&emsp;&emsp;同在2015年，Ross Girshick团队提出了Faster R-CNN，简单网络的目标检测速度达到17fps，在PASCAL VOC上准确率为59.9%；复杂网络达到5fps，准确率78.8%。&emsp;&emsp;从RCNN到Fast RCNN，再到Faster R-CNN，目标检测的四个基本步骤（候选区域生成，特征提取，分类，位置精修）终于被统一到一个深度网络框架之内。所有计算没有重复，完全在GPU中完成，大大提高了运行速度。&emsp;&emsp;Faster RCNN可以简单地看做”区域生成网络+Fast R-CNN“的系统，用区域生成网络代替Fast R-CNN中的Selective Search方法。Faster R-CNN着重解决了这个系统中的三个问题： * 1.如何设计区域生成网络 * 2.如何训练区域生成网络 * 3.如何让区域生成网络和Fast RCNN网络共享特征提取网络 &emsp;&emsp;Faster R-CNN提出了区域生成网络RPN，快速生成候选区域；通过交替训练，使RPN和Fast RCNN网络共享参数。 2 基于回归的目标检测算法&emsp;&emsp;虽然Faster R-CNN是目前主流的目标检测算法之一，但是速度上并不能满足实时的要求，随后出现YOLO，SSD这一类的算法逐渐凸显出其优略性，这类方法充分地利用了回归的思想，直接在原始图像的多个位置回归，判别出目标边框以及目标类别。 2.1 YOLO&emsp;&emsp;2016年Redmon等人提出的YOLO算法是一个可以一次性预测多个Box位置和类别的卷积神经网络，YOLO算法的网络设计延续了GoogleNet的核心思想，真正意思上实现了端到端的目标检测，并且发挥了速度快的优势，但其精度有所下滑。但在同年Redmon等人在YOLO的基础上提出了YOLO9000算法，保持了YOLO的速度，提高了准确度。主要有两方面的改进：1)在原先的YOLO检测框架上进行一系列的改进，弥补了检测精度的不足；2)提出了目标检测和目标训练和二为一的方法。YOLOv2算法的训练网络采用降采样的方法在特定的情况下可以进行动态调整，这种机制可以使网络预测不同大小的图片，让检测速度和精度之间达到平衡。 2.2 SSD&emsp;&emsp;2016年Liu等人提出SSD算法，该算法结合YOLO的回归思想以及Faster R-CNN的anchor机制做到了速度和准确率并存。最初的YOLO算法是在7x77x7的框架下识别物体，用这种框架检测小物体时，准确率会下降。在SSD算法中去掉了YOLO算法的全连接层，所以对任意大小的物体都可以检测，性能基本不变。对SSD的测试集进行训练和训练使用候选区域及用来池化的标准测试器之间最大的不同之处在于，ground truth 需要被赋予一组固定集合检测输出中某一个特定输出。当这个赋值确定之后，损失函数和后向传播就能够实现端到端的应用。总之，SSD结合了YOLO中的回归思想和Faster R-CNN中的anchor机制，使用全图各个位置的多尺度区域特征进行回归，既保持了YOLO速度快的特性，也保证了窗口预测跟Faster R-CNN一样精准。]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>计算机视觉</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MobileNetV3]]></title>
    <url>%2F2019%2F06%2F03%2FMobileNetV3%2F</url>
    <content type="text"><![CDATA[论文地址 摘要&emsp;&emsp;我们基于互补搜索技术的组合以及新颖的架构设计呈现下一代MobileNets。MobileNetV3通过硬件网络架构搜索（NAS）与NetAdapt算法相结合的方式调整到移动电话CPU，然后通过新颖的架构改进进行改进。本文开始探索自动搜索算法和网络设计如何协同工作，以利用互补的方法来改善整体的现状。通过这个过程，我们为发布创建了两个新的MobileNet模型：MobileNetV3-Large和MobileNetV3-Small，它们针对高资源和低资源使用情况。然后，这些模型被适应并应用于对象检测和语义分割的任务。对于语义分割（或任何密集像素预测）的任务，我们提出了一种新的有效分割解码器Lite Reduced Atrous Spatial Pyramid Pooling（LR-ASPP）。我们实现了移动分类，检测和分割的最新技术成果。MobileNetV3-Large在ImageNet分类上的准确度提高了3.2％，与MobileNetV2相比，延迟降低了15％。与MobileNetV2相比，MobileNetV3-Small的准确度提高了4.6％，同时将延迟降低了5％。MobileNetV3-大检测速度提高了25％，与COCO检测时的MobileNetV2大致相同。MobileNetV3-Large LR-ASPP比MobileNetV2 R-ASPP快30％，与Cityscapes细分的准确度相似。 1.简介&emsp;&emsp;高效的神经网络在移动应用程序中变得无处不在，从而实现全新的设备体验。它们也是个人隐私的关键推动因素，允许用户获得神经网络的好处，而无需将数据发送到服务器进行评估。神经网络效率的进步不仅可以通过更高的准确性和更低的延迟来改善用户体验，还可以通过降低功耗来帮助延长电池寿命。&emsp;&emsp;本文描述了我们开发MobileNetV3大型和小型模型的方法，以便提供下一代高精度高效神经网络模型，为设备上的计算机视觉提供动力。新网络推动了最新技术的发展，并演示了如何将自动搜索与新颖的架构改进相结合，以构建有效的模型。&emsp;&emsp;本文的目标是开发最佳的移动计算机视觉架构，优化移动设备上的准确度。为实现这一目标，我们引入了（1）互补搜索技术，（2）适用于移动设置的非线性高效新版本，（3）新的高效网络设计,（4）新的有效分段解码器。我们提供了彻底的实验，证明了在各种用例和手机上评估的每项技术的功效和价值。&emsp;&emsp;本文的结构如下。我们首先讨论第2节中的相关工作。第3节回顾了用于移动模型的有效构建块。第4节回顾了体系结构搜索以及MnasNet和NetAdapt算法的互补性。第5节描述了新颖的架构设计，提高了通过联合搜索找到的模型的效率。第6节介绍了分类，检测和分割的广泛实验，以便证明有效性并理解不同元素的贡献。第7节包含结论和未来的工作。 2.相关工作&emsp;&emsp;近年来，设计深度神经网络架构以实现精度和效率之间的最佳平衡是一个活跃的研究领域。新颖的手工结构和算法神经结构搜索都在推动这一领域发挥了重要作用。&emsp;&emsp;SqueezeNet[22]广泛使用1x1卷积，挤压和扩展模块主要集中在减少参数数量上。最近的工作将重点从减少参数转移到减少操作数（MAdds）和实际测量的延迟。MobileNetV1[19]采用深度可分离卷积来大幅提高计算效率。MobileNetV2[39]通过引入具有反向残差和线性瓶颈的资源有效块来扩展这一点。ShuffleNet[49]利用组卷积和信道混洗操作来进一步减少MAdds。CondenseNet[21]在训练阶段学习群组卷积，以保持层之间有用的密集连接，以便重新使用特征。ShiftNet[46]提出了与逐点卷积交织的移位操作，以取代昂贵的空间卷积。&emsp;&emsp;为了使架构设计过程自动化，首先引入强化学习（RL）来搜索具有竞争精度的高效架构[53,54,3,27,35]。完全可配置的搜索空间可以呈指数级增长并且难以处理。因此，架构搜索的早期工作集中在单元级结构搜索上，并且在所有层中重用相同的单元。最近，[43]探索了一种块级分层搜索空间，允许在网络的不同分辨率块处使用不同的层结构。为了降低搜索的计算成本，在[28,5,45]中使用可分的架构搜索框架，使用基于梯度的优化。着眼于将现有网络适应受约束的移动平台，[48,15,12]提出了更有效的自动网络简化算法。&emsp;&emsp;量化[23,25,47,41,51,52,37]是通过降低精度算法来提高网络效率的另一个重要的补充努力。最后，知识蒸馏[4,17]提供了一种额外的补充方法，可以在大型“教师”网络的指导下生成小型精确的“学生”网络。 3.高效的移动构建模块&emsp;&emsp;移动模型建立在越来越高效的构建块上。MobileNetV1[19]引入了深度可分离卷积作为传统卷积层的有效替代。深度可分离卷积通过将空间滤波与特征生成机制分离来有效地分解传统卷积。深度可分离卷积由两个单独的层定义：用于空间滤波的轻重量深度卷积和用于特征生成的较重的1x1逐点卷积。&emsp;&emsp;MobileNetV2[39]引入了线性瓶颈和倒置残差结构，以通过利用问题的低等级性质来制造更高效的层结构。该结构如图3所示，由1x1扩展卷积后跟深度卷积和1x1投影层定义。当且仅当它们具有相同数量的通道时，输入和输出才与剩余连接相连。这种结构在输入和输出处保持紧凑的表示，同时在内部扩展到更高维的特征空间，以增加非线性每通道变换的表现力。&emsp;&emsp;MnasNet[43]基于MobileNetV2结构，将基于压缩和激发的轻量级注意模块引入瓶颈结构。请注意，压缩和激励模块集成在与[20]中提出的基于ResNet的模块不同的位置。模块放置在扩展中的深度滤波器之后，以便将注意力应用于最大的表示，如图4所示。&emsp;&emsp;对于MobileNetV3，我们使用这些层的组合作为构建块，以便构建最有效的模型。层也升级了修改的swish非线性[36,13,16]。压缩和激励以及swish非线性都使用了sigmoid，这可能是低效的计算以及在定点算术中保持精度的挑战，所以我们用hard sigmoid[2,11]代替它，如5.2节所述。 4.网络搜索&emsp;&emsp;网络搜索已经证明它是发现和优化网络架构的一个非常强大的工具[53,53,5,48]。对于MobileNetV3，我们使用平台感知NAS通过优化每个网络块来搜索全局网络结构。然后，我们使用NetAdapt算法在每层中搜索过滤器的数量。这些技术是互补的，可以组合起来有效地找到给定硬件平台的优化模型。 4.1.用于分块搜索的平台遥感NAS&emsp;&emsp;]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>轻量级网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器使用指南]]></title>
    <url>%2F2019%2F05%2F29%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[查看cpu状况使用命令：top 查看gpu使用命令：gpustat 查看内存使用命令：free -m]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git将本地文件上传到github]]></title>
    <url>%2F2019%2F05%2F27%2Fgit%E5%B0%86%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%88%B0github%2F</url>
    <content type="text"><![CDATA[新建远程仓库 在本地创建文件夹初始化本地的文件夹为一个Git可以管理的仓库 1git init 将本地的仓库和远程仓库关联1git remote add origin &lt;git仓库地址&gt; 将文件夹下文件添加到仓库1git add . 可以在.gitignore中设置不上传的文件 将文件提交到仓库1git commit -m &quot;2019/5/27&quot; 将本地库的内容推送到远程1git push -u origin master origin:远程仓库名；master:分支 注意:我们第一次push的时候,加上-u参数,Git就会把本地的master分支和远程的master分支进行关联起来,我们以后的push操作就不再需要加上-u参数了]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter添加虚拟环境]]></title>
    <url>%2F2019%2F05%2F15%2Fjupyter%E6%B7%BB%E5%8A%A0%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[参考地址服务器端jupyter开启远程访问 virtualenv + jupyter notebook&emsp;&emsp;为了方便远程使用服务器，在服务器端打开了远程访问，之后需要将服务器中创建的虚拟环境添加到jupyter中。 1.进入虚拟环境 1source pytorch3/bin/activate 2.安装IPykernel 1234&lt; python2 &gt;pip install ipykernel&lt; python3 &gt;pip3 install ipykernel 3.将 Virtualenv 加入IPykernel 1234&lt; python2 &gt;python2 -m ipykernel install --user --name=myproject&lt; python3 &gt;python3 -m ipykernel install --user --name=myproject 4.启动jupyter notebook并更改kernel]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
        <tag>远程桌面</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Joint Face Detection and Alignment Using Multitask]]></title>
    <url>%2F2019%2F05%2F10%2FJoint-Face-Detection-and-Alignment-Using-Multitask%2F</url>
    <content type="text"><![CDATA[论文地址 摘要&emsp;&emsp;由于各种姿势，照明和遮挡，无约束环境中的人脸检测和对齐具有挑战性。最近的研究表明，深度学习方法可以在这两项任务上取得好的表现。在本文中，我们提出了一个深度级联多任务框架，它利用检测和对齐之间的内在联系来提高其性能。特别是，我们的框架利用级联架构，通过三个阶段精心设计的深度卷积网络，以粗略到精细的方式预测面部和地标位置。此外，我们提出了一种新的在线硬样本挖掘策略，可进一步提高实践中的性能。我们的方法在具有挑战性的人脸检测数据集和基准测试和WIDER FACE人脸检测基准测试方面取得了最先进的技术，并在面部对齐的野外基准测试中注释了面部标志，同时保持了实时性能。 简介&emsp;&emsp;面部检测和对齐对于许多面部应用至关重要，例如面部识别和面部表情分析。然而，面部的大的视觉变化，例如遮挡，大的姿势变化和极端的照明，对于实际应用中的这些任务提出了巨大的挑战。&emsp;&emsp;Viola和Jones提出的级联人脸检测器利用Haar-Like特征和AdaBoost训练级联分类器，实现了良好的性能和实时效率。但是，相当一部分工作表明，这种检测在实际应用中面对剧烈视觉变化的人脸时会显著减低表现，即使有高级的特征和分类器。基于级联结构，Mathias等人引入了用于人脸检测的可变形零件模型，并实现了卓越的性能。然而，它们在计算上是昂贵的并且通常在训练阶段需要大量的注释。最近，卷积神经网络（CNN）在各种计算机视觉任务中取得了显着进步，例如图像分类和人脸识别。受到计算机视觉任务中深度学习方法的重大成功的启发，一些研究利用深度CNN进行人脸检测。杨等人训练深层CNN进行面部属性识别，以获得面部区域的高响应，进一步产生面部候选窗口。然而，由于其复杂的CNN结构，这种方法在实践中耗时。李等人使用级联CNN进行人脸检测，但它需要从面部检测中进行边界框校准，并且需要额外的计算费用，并忽略了面部标志定位和边界框回归之间的内在相关性。&emsp;&emsp;面部对齐也吸引了广泛的研究兴趣。该领域的研究工作大致可分为两类，基于回归的方法和模板拟合方法。最近，张等人提出使用面部属性识别作为辅助任务，以使用深CNN增强面部对齐性能。&emsp;&emsp;然而，大多数先前的面部检测和面部对齐方法忽略了这两个任务之间的固有相关性。虽然现有的几个作品试图共同解决它们，但这些作品仍然存在局限性。例如，陈等人利用像素值差异的特征，与随机森林联合进行对齐和检测。但是，这些手工功能限制了它的性能。张等人使用多任务CNN来提高多视图人脸检测的准确性，但检测召回受到弱脸检测器产生的初始检测窗口的限制。&emsp;&emsp;另一方面，在训练中挖掘硬样品对于增强探测器的功率至关重要。然而，传统的硬样本挖掘通常以离线方式执行，这显着增加了手动操作。期望设计一种用于面部检测的在线硬样本挖掘方法，其自动适应当前训练状态。&emsp;&emsp;在这封信中，我们提出了一个新的框架，通过多任务学习使用统一的级联CNN来集成这两个任务。拟议的CNN包括三个阶段。在第一阶段，它通过浅CNN快速生成候选窗口。然后，它通过更复杂的CNN拒绝大量非面部窗口来细化窗口。最后，它使用更强大的CNN再次细化结果并输出五个面部标志位置。由于这个多任务学习框架，算法的性能可以显着提高。本函的主要贡献概括如下： (1) 我们提出了一种新的级联CNNs框架，用于联合面部检测和对齐，并精心设计轻量级CNN架构以实现实时性能。 (2) 我们提出了一种有效的方法来进行在线硬样本挖掘，以提高性能。 (3) 在具有挑战性的基准测试中进行了广泛的实验，以显示与人脸检测和面部对齐任务中的最新技术相比所提出的方法的显着性能改进。 方法 总体框架&emsp;&emsp; CNN结构&emsp;&emsp; 训练&emsp;&emsp; 实验&emsp;&emsp;]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CondenseNet]]></title>
    <url>%2F2019%2F05%2F09%2FCondenseNet%2F</url>
    <content type="text"><![CDATA[论文地址代码地址 1. 简介&emsp;&emsp; 2. 相关工作 &emsp;&emsp; 3. CondenseNets&emsp;&emsp;在DenseNet的基础上使用1x1的分组卷积效果不好，作者认为这是由使用前面的特征图与当前特征图合并做输入引起的。这与典型的卷积输入有两点不同：1.它们有固定的秩序，2.它们更加多样化。不相关组的特征分配会妨碍特征在网络的再利用。作者对输入的特征图进行随机置换减小了对准确性的负面影响，但在相同的计算成本下比smaller DenseNets准确率低。&emsp;&emsp;在DenseNet中已经证明：将早期的特征作为后期层的输入对特征重用是十分有效的。但是并不是所有的早期特征对随后的层有影响，很难预测哪些特征应该被使用。为了解决这个问题，我们提出了一种在训练中自动学习输入特征分组的方法。学习组结构允许每个滤波器选择它自己最相关的一组输入。 3.1 学习组卷积&emsp;&emsp;我们通过多阶段过程学习组卷积，如图3和图4所示。训练迭代的前半部分包括压缩阶段。在这里，我们重复训练网络，稀疏诱导正则化，进行固定次数的迭代，然后修剪掉具有权重比较低的不重要滤波器。培训的后半部分包括优化阶段，我们在分组修复后学习过滤器。执行修剪时，我们确保来自同一组的过滤器共享相同的稀疏模式。结果，一旦训练完成（测试阶段），可以使用标准组卷积来实现稀疏化层。由于组卷积由许多深度学习库有效实现，因此在理论上和实践中都可以节省大量计算量。我们将在下面介绍我们的方法。 滤波器分组&emsp;&emsp;卷积过程用4D张量$O\times R\times W\times H$表示，其中O表示输出通道数，R表示输入通道数，W和H表示滤波器的长宽。训练前将滤波器分为相同大小的G组，$F_{ij}^{g}$表示组g内第i个输出的第j个输入的权重。 压缩标准&emsp;&emsp;在训练过程中，筛选出没组中不重要的输入特征的子集。第j个输入特征的对于滤波器组g的重要性通过它在组内所有输出之间的权重的平均值来评估，即$\sum_{i=1}^{O/G}{|F_{ij}^{g}|}$，换句话说，如果它们的L1范数比其他列的L1范数小，则我们删除$F^{g}$中的列（通过将它们归零）。这使卷积层在结构上稀疏：来自同一组的滤波器总是接收与相同的特征输入。 Group Lasso&emsp;&emsp;为减少权重修剪带来的负面影响，L1正则化通常用来诱导稀疏性。为了是同一组滤波器有相同的稀疏输入，我们使用以下的组稀疏性计算方法： \sum_{g=1}^{G}\sum_{j=1}^{R}\sqrt{\sum_{i=1}^{O/G}{F_{ij}^{g}}^2}&emsp;&emsp;组正则化将$F_{g}$中所有的元素置为0，因为平方根中的项由该列中的最大元素控制。这会使模型向组水平的稀疏方面发展。 压缩因子&emsp;&emsp;除了学习组卷积能够自动发现良好的连接模式之外，它们还比标准组卷积更灵活。 特别是，组使用的特征图的比例不一定需要是1/G。 我们定义了一个可能与G不同的凝聚因子C，并允许每个组选择输入的R/C。 压缩步骤&emsp;&emsp;与在预训练网络中修剪权重的方法相比，我们的权重修剪过程被整合到训练过程中。 如图3所示（使用C = 3），在每个C-1压缩阶段结束时，我们修剪滤波器权重的1/C。 在训练结束时，每个滤波器组中仅保留1/C的权重。 在我们的所有实验中，我们将凝聚阶段的训练时期的数量设置为$M/2(c-1)$，其中M表示训练时期的总数 ，使得训练时期的前半部分用于压缩。 在训练过程的后半部分，优化阶段，我们训练了稀疏模型。（实际操作中将剪掉的分支置为0）。 学习率&emsp;&emsp;我们采用Loshchilov等人的余弦形状学习率表。它可以平滑地退化学习率，并且通常可以提高准确度。 图4将学习率显示为训练时期（品红色）的函数，以及在CIFAR-10数据集上训练的CondenseNet的相应训练损失（蓝色曲线）。在时期150处的损失的突然增加是由最终的冷凝操作引起的，其消除了剩余重量的一半。 然而，该图显示该模型在优化阶段从该修剪步骤逐渐恢复。 索引层&emsp;&emsp;在训练完成后，我们移除修剪的权重并将稀疏模型转化为具有常规模式的网络，在图三的测试步骤中可以看到索引层。索引层在输入滤波器重新排列进行输出，以便于现有的常规组卷积的实现。图1显示了训练期间（中间）和测试期间（右侧）CondenseNet层的转换。 在训练期间，1×1卷积是学习组卷积（L-Conv），但在测试期间，在索引层的帮助下，它变为标准组卷积（G-Conv）。 3.2 网络设计&emsp;&emsp;除了使用上面介绍的学习组卷积之外，我们还对常规DenseNet架构进行了两处更改。这些更改旨在进一步简化体系结构并提高其计算效率。图5说明了我们对DenseNet架构所做的两项更改。 增长增长率&emsp;&emsp;原始的DenseNet设计每层增加$k$个特征图，表示增长率。在DenseNet中，较深的层更依赖于高水平的特征而不是低水平的特征，这激励我们提高网络的捷径连接。我们发现可以通过随深度增长而提高增长率来实现。这增加了后期层相对于前面层的比率。将增长率变化设置为$k=2^{m-1}k_{0}$，其中m是密集块的索引，k0是常量。 这种设定增长率的方式不会引入任何额外的超参数。 “增长增长率”（IGR）策略在模型的后续层中放置了更大比例的参数。 这大大提高了计算效率，但在某些情况下可能会降低参数效率。根据具体的硬件限制而定。 完全密集连接&emsp;&emsp;为了鼓励功能重用，甚至比原来的DenseNet架构更多，我们将输入层连接到网络中的所有后续层，即使这些层位于不同的密集块中（参见图5）。由于密集块具有不同的特征分辨率，因此当我们使用平均池作为低分辨率层的输入时，我们对具有更高分辨率的特征映射进行下采样。 4 实验&emsp;&emsp;]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>轻量级网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vnc操作]]></title>
    <url>%2F2019%2F03%2F21%2Fvnc%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[参考博客 查看vnc进程：1ps -ef | grep vnc 杀掉vnc进程1vncserver -kill :9 使用指定分辨率启动vnc1vncserver -geometry 1920x1080 :43 查看vnc帮助1vnc -help]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
        <tag>远程桌面</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Residual Attention Network]]></title>
    <url>%2F2019%2F03%2F18%2FResidual-Attention-Network%2F</url>
    <content type="text"><![CDATA[论文地址 摘要&emsp;&emsp;在这个工作中，我们提出了“残差注意网络”，它是一种使用注意力机制的卷积神经网络，能够将最先进的前馈神经网络机制融合到端对端的训练中。我们的残差注意网络是由生成注意力感知特征的注意力模块堆叠而成的。注意力感知特征会随着层数的加深自适应地改变。在每个注意力模块的内部，自上而下自下而上的前馈结构能够将前馈和反馈结构展开到单个的前馈过程中。重要的事，我们提出的注意力残差学习非常深的残差注意网络，能够轻松地扩展到数百层。&emsp;&emsp;我们对CIFAR-10和CIFAR-100数据集进行了广泛的分析，以验证上述每个模块的有效性。我们的剩余注意力网络在三个基准数据集上实现了最先进的物体识别性能，包括CIFAR-10（3.90％误差），CIFAR-100（20.45％误差）和ImageNet（4.8％单一模型和单一作物，顶部 - 5错误）。请注意，与ResNet-200相比，我们的方法实现了0.6％的前1精度提升，46％的主干深度和69％的前向FLOP。该实验还表明，我们的网络可以抵御嘈杂的标签。 1 介绍&emsp;&emsp;不止是友好的脸，而且红色也会引起我们的注意。在之前的文献中已经广泛地研究了混合特征。注意力不仅服务于选择聚焦位置，而且鼓励该位置处目标的不同表示。之前的工作将注意力漂移作为一个序列过程来捕捉不同的参与方面。然而，据我们所知，在图像分类任务没有注意力机制中被应用于前馈网络结构来实现最先进的结果。最近在图像分类任务的先进工作都是致力于使用非常深的结构训练前馈神经网络。&emsp;&emsp;受到注意力机制和深度神经网络进步的鼓舞，我们提出了残差注意力网络(RAN)，一种使用混合注意力机制的非常深的结构。RAN是由多个能够生成注意力感知特征的注意力模块组成。随着层数的加深，来自不同模块的注意力特征会自适应地改变。&emsp;&emsp;除了注意力机制带来的更具辨别力的特征表示外，我们的模型还具有以下吸引人的特性：（1）增加注意力模块导致模型能力提升，因为不同种类的注意力被广泛地捕获。图一显示了在热气球图片上不同种类注意力。天空注意力掩膜虚化了背景表现，气球底部的注意力掩膜突出了气球的底部。（2）它使得端对端的训练方式可以融入到最先进的深度网络结构中。特别地，我们的网络可以扩展到数百层。我们的残留注意网络在CIFAR-10，CIFAR-100和具有挑战性的ImageNet图像分类数据集上超越了最先进的残留网络，显着减少了计算（69％前向FLOP）。&emsp;&emsp;所有上述方法可以通过以下方法实现：（1）堆叠网络结构：我们的RAN通过堆叠注意力模块组成。堆叠结构是混合注意力机制的基本应用，因此，不同类别的注意力能够被不同的注意力模块捕获。（2）注意力残差学习：直接堆叠注意模块会导致明显的性能下降。因此，我们提出了注意力残留学习机制来优化具有数百层的非常深的残留注意网络。（3）自上而下自下而上的前馈注意力机制：自上而下自下而上的前馈结构以及成功用于人类行为检测和图像分割。我们使用这种结构作为注意力模块的一部分，用来在功能上添加软权重。这种结构可以在单个前馈过程中模拟自下而上的快速前馈过程和自上而下的注意反馈，这使我们能够自上而下地开发端到端的可训练网络。我们工作中自下而上自上而下的结构与堆叠沙漏网络的不同之处在于其引导特征学习的意图。 2 相关工作&emsp;&emsp;来自人类感知过程的证据[23]显示了注意机制的重要性，它使用顶级信息来指导自下而上的前馈过程。 最近，已经尝试将注意力应用于深度神经网络。 Deep Boltzmann Machine（DBM）[21]通过其在训练阶段的重建过程包含自上而下的关注。 注意机制也被广泛应用于递归神经网络（RNN）和长期短期记忆（LSTM）[13]，以解决顺序决策任务[25,29,21,18]。按顺序收集信息并决定下个特征学习步骤的关注内容。&emsp;&emsp;残差学习致力于学习身份映射间的残差。 该技术极大地增加了前馈神经网络的深度。 与我们的工作类似，[25,29,21,18]使用残余学习和注意机制来从残余学习中受益。 使用注意机制捕获两个信息源（查询和查询上下文）以在他们的工作中互相帮助。 在我们的工作中，单个信息源（图像）被分成两个不同的信息源并重复组合。 并且应用残差学习来缓解重复分裂和组合带来的问题。&emsp;&emsp;在图像分类中，使用不同的方法应用自上而下的注意机制：顺序过程，区域建议和控制门。 顺序过程[23,12,37,7]将图像分类建模为顺序决策。 因此，可以类似地应用以上注意力。 该公式允许使用RNN和LSTM进行端到端优化，并且可以以目标驱动的方式捕获不同类型的注意力。&emsp;&emsp;区域提案[26,4,8,38]已成功应用于图像检测任务。 在图像分类中，在前馈分类之前添加附加区域建议阶段。 建议的区域包含最高信息，并在第二阶段用于特征学习。 与区域提案依赖于大量监督的图像检测不同，例如 地面真实边界框或详细的分割掩模[6]，无监督学习[35]通常用于生成图像分类的区域提议。&emsp;&emsp;控制门被广泛地用于LSTM中，在注意力图像分类中，用顶层信息更新神经元的控制门，并且在训练期间影响前馈过程[2,30]。 然而，在训练步骤中涉及新过程，强化学习[30]或优化[2]。 Highway Network[29]扩展了控制门，解决了深度卷积神经网络的梯度退化问题。&emsp;&emsp;然而，图像分类的最新进展侧重于使用“非常深”结构训练前馈卷积神经网络[27,33,10]。 前馈卷积网络模拟人类皮层的自下而上的路径。 已经提出了各种方法来进一步提高深度卷积神经网络的判别能力。 VGG [27]，Inception [33]和残差学习[10]被提出来训练非常深的神经网络。 随机深度[14]，批量标准化[15]和Dropout [28]利用正则化进行收敛并避免过度拟合和退化。&emsp;&emsp;在最近的工作[3,17]中产生的软关注可以对卷积网络进行端到端的训练。 我们的剩余注意力网络以创新的方式将快速发展的前馈网络结构中的软关注融入其中。 最近提出的空间变换器模块[17]实现了关于门牌号识别任务的最新结果。 捕获顶部信息的深度网络模块用于生成仿射变换。 仿射变换应用于输入图像以获得关注区域，然后馈送到另一个深度网络模块。 通过使用可执行空间变换的可微网络层，可以端到端地训练整个过程。 注意尺度[3]使用软注意作为比例选择机制，并在图像分割任务中获得最先进的结果。&emsp;&emsp;我们的残留注意网络中软关注结构的设计受到最近开发的定位任务的启发，即分割[22,25,1]和人体姿态估计[24]。 这些任务激励研究人员使用细粒度特征图来探索结构。 框架倾向于级联自下而上和自上而下的结构。 自下而上的前馈结构产生具有强语义信息的低分辨率特征映射。 之后，自上而下的网络产生密集的特征，以推断每个像素。 在底部和顶部特征图之间采用跳过连接[22]，并在图像分割上实现了最先进的结果。 最近堆叠的沙漏网络[24]融合了来自多个尺度的信息，以预测人体姿势，并从编码全局和本地信息中获益。 3 RAN&emsp;&emsp;我们的残差注意网络是由叠加注意力模块组成的。每个注意力模块可以分为两个分支：主干分支和掩膜分支。主干分支用于特征提取，并且能够使用任何最先进的网络结构。在这个工作中，我们使用预激活的残差单元ResNeXt和Inception作为我们RAN网络的基础单元来组成注意力模块。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>attention</tag>
        <tag>图像分类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络结构汇总]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[本文收集了一些神经网络的架构，包含常用的一些模型。 LeNet51.Input&emsp;&emsp;输入图像统一归一化为32*32。2.C1卷积层&emsp;&emsp;经过(5*5*1)*6卷积核，stride=1, 生成featuremap为28*28*6。3.S2池化层&emsp;&emsp;经过(2*2)采样核，stride=2，生成featuremap为14*14*6。4.C3卷积层&emsp;&emsp;经过(5*5*6)*16卷积核，stride=1，生成featuremap为10*10*16。5.S4池化层&emsp;&emsp;经过(2*2)采样核，stride=2，生成featuremap为5*5*16。6.C5卷积层&emsp;&emsp;经过(5*5*16)*120卷积核，stride=1， 生成featuremap为1*1*120。7.F6全连接层&emsp;&emsp;输入为1*1*120，输出为1*1*84，总参数量为120*84。8.Output全连接层。&emsp;&emsp;输入为1*1*84，输出为1*1*10，总参数量为84*10。10就是分类的类别数。 AlexNet1.Input&emsp;&emsp;输入图像为227*227*3。2.Conv1&emsp;&emsp;经过(11*11*3)*96卷积核，stride=4， (227-11)/4+1=55，生成featuremap为55*55*96。3.Pool1&emsp;&emsp;经过3*3的池化核，stride=2，(55-3)/2+1=27，生成featuremap为27*27*96。4.Norm1&emsp;&emsp;local_size=5，生成featuremap为27*27*96。5.Conv2&emsp;&emsp;经过(5*5*96)*256的卷积核，pad=2，group=2，(27+2*2-5)/1+1=27，生成featuremap为27*27*256。6.Pool2&emsp;&emsp;经过3*3的池化核，stride=2，(27-3)/2+1=13，生成featuremap为13*13*256。7.Norm2&emsp;&emsp;local_size=5, 生成featuremap为13*13*256。8.Conv3&emsp;&emsp;经过(3*3*256)*384卷积核，pad=1， (13+1*2-3)/1+1=13，生成featuremap为13*13*384。9.Conv4&emsp;&emsp;经过(3*3*384)*384卷积核，pad=1，(13+1*2-3)/1+1=13，生成featuremap为13*13*384。10.Conv5&emsp;&emsp;经过(3*3*384)*256卷积核，pad=1，(13+1*2-3)/1+1=13，生成featuremap为13*13*256。11.Pool5&emsp;&emsp;经过(3*3)的池化核，stride=2，(13-3)/2+1=6，生成featuremap为6*6*256。12.Fc6&emsp;&emsp;输入为(6*6*256)*4096全连接，生成featuremap为1*1*4096。13.Dropout6&emsp;&emsp;在训练的时候以1/2概率使得隐藏层的某些神经元的输出为0，这样就丢掉了一半节点的输出，BP的时候也不更新这些节点，以下Droupout同理。14.Fc7&emsp;&emsp;输入为1*1*4096，输出为1*1*4096，总参数量为4096*4096。15.Dropout7&emsp;&emsp;生成featuremap为1*1*4096。16.Fc8&emsp;&emsp;输入为1*1*4096，输出为1000，总参数量为4096*1000。 总结: 1.网络比LeNet更深，包括5个卷积层和3个全连接层。2.使用relu激活函数，收敛很快，解决了Sigmoid在网络较深时出现的梯度弥散问题。3.加入了dropout层，防止过拟合。4.使用了LRN归一化层，对局部神经元的活动创建竞争机制，抑制反馈较小的神经元放大反应大的神经元，增强了模型的泛化能力。5.使用裁剪翻转等操作做数据增强，增强了模型的泛化能力。预测时使用提取图片四个角加中间五个位置并进行左右翻转一共十幅图片的方法求取平均值，这也是后面刷比赛的基本使用技巧。6.分块训练，当年的GPU没有这么强大，Alexnet创新地将图像分为上下两块分别训练，然后在全连接层合并在一起。7.总体的数据参数大概为240M。 VGG 1.Input层&emsp;&emsp;输入图片为224*224*3。2.CONV3-64&emsp;&emsp;经过（3*3*3）*64卷积核，生成featuremap为224*224*64。3.CONV3-64&emsp;&emsp;经过（3*3*64）*64卷积核，生成featuremap为224*224*64。4.Max pool&emsp;&emsp;经过（2*2）max pool核，生成featuremap为112*112*64。5.CONV3-128。&emsp;&emsp;经过（3*3*64）*128卷积核，生成featuremap为112*112*128。6.CONV3-128&emsp;&emsp; 经过（3*3*128）*128卷积，生成featuremap为112*112*128。7.Max pool&emsp;&emsp;经过（2*2）maxpool，生成featuremap为56*56*128。8.CONV3-256&emsp;&emsp;经过（3*3*128）*256卷积核，生成featuremap为56*56*256。9.CONV3-256&emsp;&emsp;经过（3*3*256）*256卷积核，生成featuremap为56*56*256。10.CONV3-256&emsp;&emsp;经过（3*3*256）*256卷积核，生成featuremap为56*56*256。11.Max pool&emsp;&emsp;经过（2*2）maxpool，生成featuremap为28*28*256。12.CONV3-512&emsp;&emsp;经过（3*3*256）*512卷积核，生成featuremap为28*28*512。13.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为28*28*512。14.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为28*28*512。15.Max pool&emsp;&emsp;经过（2*2）maxpool,生成featuremap为14*14*512。16.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为14*14*512。17.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为14*14*512。18.CONV3-512&emsp;&emsp;经过（3*3*512）*512卷积核，生成featuremap为14*14*512。19.Max pool&emsp;&emsp;经过2*2卷积，生成featuremap为7*7*512。20.FC-4096&emsp;&emsp;输入为7*7*512，输出为1*1*4096，总参数量为7*7*512*4096。21.FC-4096&emsp;&emsp;输入为1*1*4096，输出为1*1*4096，总参数量为4096*4096。22.FC-1000&emsp;&emsp;输入为1*1*4096，输出为1000，总参数量为4096*1000。 总结: 1. 共包含参数约为550M。2. 全部使用3*3的卷积核和2*2的最大池化核。3. 简化了卷积神经网络的结构。 MobileNet]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习，计算机视觉，CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试问题收集]]></title>
    <url>%2F2019%2F01%2F23%2F%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[GItHub使用指南GitHub 编辑指导GItHub 公式编辑Markdown 教程 计算机视觉面试问题SVMCNN常见网络收集 softmax函数attentiondata augmentation损失函数随机梯度下降交叉熵正则化泰勒公式Batch Normalization网络参数是如何计算的ShuffleNetdeepwise separable conv最优化方法深度神经网络全面概述：从基本概念到实际模型和硬件基础数学概念RNNLSTMRPNPCAK_meansKNN损失函数梯度消失和梯度弥散SITFDropoutPooling正则化数据结构和算法问题网络协议 线性代数堆和栈的区别计算机视觉及深度学习岗位应聘问题]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>计算机视觉</tag>
        <tag>面试</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode刷题总结]]></title>
    <url>%2F2019%2F01%2F23%2FLeetCode%E5%88%B7%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1 数组用法123456789101112//元素交换swap(a[1], a[3]);//sort排序sort(a.begin(),a.end());//数组颠倒reverse(a.begin(), a.end());//数组元素置为0memset(a, 0, a.size());//数组取值a.push_back();//定义二维数组vector&lt; vector&lt;int&gt; &gt; result 2 set集合的用法集合中没有重复元素 12345678910111213141516//定义一个int类型的集合set&lt;int&gt; s;set&lt;int&gt;::iterator it;//插入元素10（插入的数值默认从小到大排序）s.insert(10);//删除元素10s.erase(10);//清空集合s.clear();//集合元素的个数s.size();//判断集合是否为空s.empty();//查找集合中是否与元素10，有的话返回10，没有则返回s.end()it = s.find(10);// mutiset：多重集合与set最大的区别是它可以插入重复元素，如果删除的话，相同的会一起删除，如果查找的话，返回该元素的迭代器的位置，若有相同，返回第一个元素的地址，其它使用和set基本类似。 3 map用法c++中map中的元素按key升序排列，基本格式为map m，需要使用头文件#include。 12345//数据的插入map&lt;int, string&gt; studentsID;studentsID.instert(pair&lt;int, string&gt;(1, "student_one"));studentsID.instert(map&lt;int, string&gt;::value_type(2, "student_two"));studentID[3]="student_three"; 4 字符串12345678//排序sort(a.begin(), a.end());//将所有字符转换成小写transform(s.begin(), s.end(), s.begin(),::tolower);//截取字符串//标准库的string有一个substr函数用来截取子字符串。一般使用时传入两个参数，第一个是开始的坐标（第一个字符是0），第二个是截取的长度。string name("rockderia");string firstname(name.substr(0,4)); 5 运算异或（^）：二进制数进行运算相同为0，不同为1与运算（&amp;）：同时为1，才为1；或运算（|）：同时为0，才为0；取反（~）左移（&lt;&lt;）：左边的二进制丢失，右边补0，左移最高位不包括1，左移相当于该数乘2；右移（&gt;&gt;）:正数左补0，负数左补1不同长度的数据进行位运算时，系统会自动补齐。 6 栈栈具有先进后出的特性 123456789101112131415// 默认构造函数stack&lt;int&gt; s;// 复制构造函数stack&lt;int, list&lt;int&gt;&gt; s1;stack&lt;int, list&lt;int&gt;&gt; s2(s1);// 入栈s.push();// 出栈，不会显示内容s.pop();// 提取栈顶元素s.top();// 判断是否非空s.empty() // true表示未空，false表示非空// 返回栈中数目s.size() 7 队列1234567891011121314// 定义队列queue&lt;int&gt; q;// 入队q.push(x)// 出队q.pop()// 访问队首元素q.front()// 访问队尾元素q.back()// 判断队列是否为空q.empty()// 访问队列中元素个数q.size() 队列具有先进先出的特性]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>LeetCode</tag>
        <tag>编程</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy.random函数的一些用法]]></title>
    <url>%2F2019%2F01%2F23%2Fnumpy-random%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考博客 numpy.random.rand()numpy.random.rand(d0, d1, …, dn) rand函数根据给定维度生成[0,1)之间的数据，包含0，不包含1 dn表示每个维度 返回值为指定维度的array 输入 1np.random.rand(4, 2) # 生成4行两列0-1之间的随机数 输出 1234array([[ 0.2639652 , 0.67762924], [ 0.50164586, 0.73739781], [ 0.18457953, 0.85558988], [ 0.16193526, 0.83935579]]) 输入 1np.random.rand(4, 3, 2) # shape为[4, 3, 2] 输出 123456789101112131415array([[[ 0.49636822, 0.89954378], [ 0.5711387 , 0.41691163], [ 0.05681485, 0.88512829]], [[ 0.88798283, 0.96294557], [ 0.91100035, 0.28982022], [ 0.90098484, 0.85539872]], [[ 0.99124126, 0.87069271], [ 0.82365864, 0.33025856], [ 0.8874623 , 0.22067393]], [[ 0.62666929, 0.71956291], [ 0.81974729, 0.46510244], [ 0.03494486, 0.11045034]]]) numpy.random.randn()numpy.random.randn(d0,d1,…,dn) randn函数返回一个或一组样本，具有标准正态分布. dn表示每个维度 返回值为指定维度的array 标准正态分布是以0为均值，1为标准差的正态分布，记为N(0, 1)。 1np.random.randn(4, 2) 1-0.599153380810341 1np.random.randn(4, 2) 1234array([[-0.83173279, -0.06084999], [ 0.30143042, -0.63863605], [-0.45491282, 0.72084355], [-0.86603523, 1.14210338]]) 1np.random.randn(4, 3, 2) 123456789101112131415array([[[ 0.62674807, -0.40911062], [-0.65785551, 0.85653665], [-0.55250578, 1.15478597]], [[-1.39797824, 1.36343765], [-0.35807181, 2.08002524], [-0.16746821, 1.89978231]], [[-0.89490747, -0.49563846], [ 0.36720155, -0.30631295], [ 0.43208381, 1.04328295]], [[-0.65629808, 0.501748 ], [ 0.30889304, -0.52872014], [ 0.04584062, -0.05242994]]]) numpy.random.randint()numpy.random.randint(low, high=None, size=None, dtype=’l’) 返回随机整数，范围区间为[low,high），包含low，不包含high 参数：low为最小值，high为最大值，size为数组维度大小，dtype为数据类型，默认的数据类型是np.int high没有填写时，默认生成随机数的范围是[0，low) 1np.random.randint(1, size=5) 1array([0, 0, 0, 0, 0]) 1np.random.randint(1, 5) 12 1np.random.randint(-5, 5, size=[2,2]) 12array([[ 1, 0], [-3, 2]]) numpy.random.random_integersnumpy.random.random_integers(low, high=None, size=None) 返回随机整数，范围区间为[low,high]，包含low和high 参数：low为最小值，high为最大值，size为数组维度大小 high没有填写时，默认生成随机数的范围是[1，low] 1np.random.random_integers(5, size=5) 1array([5, 4, 2, 3, 1]) 生成[0,1)之间的浮点数 numpy.random.random_sample(size=None) numpy.random.random(size=None) numpy.random.ranf(size=None) numpy.random.sample(size=None) 12345678print('-----------random_sample--------------')print(np.random.random_sample(size=(2,2)))print('-----------random--------------')print(np.random.random(size=(2,2)))print('-----------ranf--------------')print(np.random.ranf(size=(2,2)))print('-----------sample--------------')print(np.random.sample(size=(2,2))) 123456789101112-----------random_sample--------------[[ 0.19678647 0.64750281] [ 0.70380805 0.18626702]]-----------random--------------[[ 0.05688147 0.57224742] [ 0.5821726 0.8344959 ]]-----------ranf--------------[[ 0.57307708 0.08199258] [ 0.50676558 0.79959829]]-----------sample--------------[[ 2.25676224e-04 8.76885950e-01] [ 7.52204914e-01 6.43694560e-01]] numpy.random.choice()numpy.random.choice(a, size=None, replace=True, p=None) 从给定的一维数组中生成随机数 参数： a为一维数组类似数据或整数；size为数组维度；p为数组中的数据出现的概率 a为整数时，对应的一维数组为np.arange(a) 1np.random.choice(5, 3) 1array([4, 4, 2]) 123np.random.choice(5, 3, replace=False)# replace为False时，生成的数不能有重复的 1array([0, 3, 1]) 1np.random.choice(4, 4, replace=False) 1array([1, 0, 2, 3]) 1234np.random.choice(4, size=(3, 2))array([[2, 1], [2, 3], [1, 1]]) 12demo_list = ['lenovo', 'sansumg','moto','xiaomi', 'iphone']np.random.choice(demo_list,size=(3,3)) 1234array([['lenovo', 'sansumg', 'lenovo'], ['moto', 'sansumg', 'sansumg'], ['sansumg', 'iphone', 'moto']], dtype='&lt;U7') 123# p是指定每个元素的概率，概率和应为1，且数据个数与a应该相同demo_list = ['lenovo', 'sansumg','moto','xiaomi', 'iphone']np.random.choice(demo_list,size=(3,3), p=[0.1,0.6,0.1,0.1,0.1]) 1234array([['sansumg', 'sansumg', 'iphone'], ['sansumg', 'sansumg', 'xiaomi'], ['sansumg', 'sansumg', 'sansumg']], dtype='&lt;U7') numpy.random.seed() np.random.seed()的作用：使得随机数据可预测。 当我们设置相同的seed，每次生成的随机数相同。如果不设置seed，则每次会生成不同的随机数 1234567for i in range(10): np.random.seed(2) print(np.random.rand(5)) print(np.random.rand(5)) print(np.random.rand(5)) print(np.random.rand(5)) print() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548][ 0.4359949 0.02592623 0.54966248 0.43532239 0.4203678 ][ 0.33033482 0.20464863 0.61927097 0.29965467 0.26682728][ 0.62113383 0.52914209 0.13457995 0.51357812 0.18443987][ 0.78533515 0.85397529 0.49423684 0.84656149 0.07964548]]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShuffleNetV2]]></title>
    <url>%2F2019%2F01%2F23%2FShuffleNetV2%2F</url>
    <content type="text"><![CDATA[论文地址 摘要&emsp;&emsp;近年来，神经网络的结构设计极大地被间接度量计算复杂度（如FLOPs）导向，直接度量速度还会被其它因素诸如内存存取消耗和平台特性所影响。因此，我们的工作打算计算目标平台的直接度量，而不仅仅考虑间接度量FLOPs。基于一系列的限制性实验，我们的工作获得了一些有效的网络设计的实用指南。相应地，我们提出了ShuffleNet V2这种新的网络结构。进行了全面的消融实验后，我们证实了在速度和准确率进行权衡的情况下，ShuffleNet V2是最先进的。 1 介绍 &emsp;&emsp;深度神经网络经过最近几年的发展变得更加准确和更加快速。但是在高准确率下计算复杂度这个重要问题被忽略了。实际任务中要求在目标平台（如硬件）和应用场景（如需要低延迟的自动驾驶）这些计算有限制的情况下得到最高的准确率。这激励了一些轻量级网络的研究，并且需要在速度和准确率之间做更好地平衡，此类网络有Xception,MobileNet,MobileNet V2,ShuffleNet和CondenseNet。这些工作中分组卷积和深度卷积有十分重要的作用。&emsp;&emsp;计算复杂度采用最广泛的度量是FLOPs。但FLOPs是一个间接度量。它只是一个近似值，而且和我们关注的直接度量如速度或延迟通常情况下是不等的，这种差异已经被许多工作证实。因此，仅仅使用FLOPs作为复杂度度量是不充分的，并且会导致设计的架构不是最优的。&emsp;&emsp;导致间接度量（FLOPs）和直接度量（速度）的差异主要有两个。首先FLOPs没有顾忌对速度有影响的几个重要因素。一个因素是内存访问消耗，这种消耗在某些操作比如分组卷积占有很大一部分运行时间,这可能是大型设备比如GPU的瓶颈。这个成本在网络架构设计的时候不能被忽略。另一个因素是并行度。在相同的FLOPs下，高并行度的网络比低并行度的网络运行更快。&emsp;&emsp;另一个因素是相同的FLOPs需要的运行时间不同,这取决于平台。比如，张量分解被广泛地用于早期的加速矩阵乘法运算。但是最近的研究发现分解在减少了75%FLOPs的情况下在GPU上的速度更慢。我们调查发现最新的CUDNN对3x3的卷积会进行特殊优化，并不能确定3x3的卷积一定比9个1x1的卷积速度慢。&emsp;&emsp;根据这些观察结果，我们提出了两个应该被并用于有效网络架构设计的原则。第一，使用直接度量代替间接度量；第二，在目标平台上计算相同的度量。&emsp;&emsp;在我们的工作中，我们遵循这两个原则并提出了一个更有效的网络架构。在第二部分，我们首先分析了两个具有代表性的先进网络的运行时间。之后，我们获得了四个有效网络设计的指导方针，这些方针超出了FLOPs的考虑范围，而且与平台无关。我们使用专门优化的代码在两个平台（GPU和ARM）上做了一系列控制实验去证实他们，确信我们的结果是最先进的。&emsp;&emsp;在第三部分，根据指导方针，我们设计了一个新的网络结构。它是ShuffleNet网络的衍生版本，名为ShuffleNet V2。经过第四部分全面的实验后证实ShuffleNet V2在所有的平台上比之前的网络更快更准确。 2 有效网络设计的实际指导方针&emsp;&emsp;我们的研究是在两个广泛采用的硬件上对CNN库进行工业级优化。我们注意到我们的CNN库比大部分开源的CNN库更有效，因此，我们确信我们的观察结果和结论是有力的并且在工业中实践是有意义的。 &emsp;&emsp;其它的设置包括：打开所有的优化项（比如：用于减少小运算带来的计算开支的张量融合）。图片的输入尺寸是$224\times 224$。每个网络进行随机初始并计算100次，采用平均运行时间。&emsp;&emsp;在开始我们的工作前，我们先分析了目前两个最先进的网络ShuffleNet V1和MobiileNet V2的运行时间。它们在ImageNet分类任务中都十分有效和准确。并且它们都被低端设备比如手机广泛应用。虽然我们仅分析这两个网络，但这两个网络代表了现在的趋势。它们的核心是分组卷积和深度卷积，这些操作是目前先进网络的重要组成部分，比如ResNeXt,Xception,MobileNet和CondenseNet。&emsp;&emsp;综合的运行时间被不同的运算分解，如图2，我们注意到FLOPs度量仅仅计算卷积部分的花费。尽管卷积占所有运算的大部分，但是其它的运算包括数据输入输出，数据混洗以及逐元素运算也占据了大量的时间。FLOPs不能够精准地评估运算时间。&emsp;&emsp;基于这个观察结果，我们从不同的方面对运行时间提出了细节的分析，并且获得了几个有效网络架构设计的指导指南。 G1)相同的通道可以最小化内存存取消耗&emsp;&emsp;现在的网络通常采用深度分离卷积，在深度分离卷积中，1x1的卷积占据了绝大部分复杂度。我们开始研究1x1卷积。1x1卷积由两个参数来表示，输入通道数$c_{1}$,输出通道数为$c_{2}$。h和w是特征图的长和宽，1x1卷积的FLOPs是 B=hwc_{1}c_{2}&emsp;&emsp;为了简化计算，我们假定计算设备足够存储全部的特征图和参数，这样的话，内存存储消耗 MAC=hw(c_{1}+c_{2})+c_{1}c_{2}&emsp;&emsp;从均值不等的情况，我们可以得出: MAC\geq 2\sqrt{hwB}+\frac{B}{hw}(1)&emsp;&emsp;从公式（1）可以看出，MAC的下限被FLOPs捆绑，输入通道数等于输出通道数的时候MAC达到最小。&emsp;&emsp;这个结论只是理论上，实际中很多设备的缓存没有假设的那么大，而且现代计算库通常采用复杂的阻塞策略来充分利用缓存机制。因此，真实的MAC值肯能会偏离理论上的值。为了证实我们的结论，我们随后进行了实验，通过重复堆叠10个构建块来构建基准网络，每一个块包括两个卷积层，第一层输入通道为$c_{1}$，输出通道为$c_{2}$，下一层网络与之相反。&emsp;&emsp;表1展示了实验结果，当输入输出通道数比值为1：1时，可以看出MAC值会变得更小并且网络计算速度会更快。 G2)过大的分组卷积会提高MAC&emsp;&emsp;目前分组卷积是很多先进网络的核心部分，它通过将密集卷积的通道分组进行卷积来减少计算复杂度（FLOPs），因此它可以在与传统结构在FLOPs相同的情况下使用更多的通道，进而提升模型的性能。但是，提升的通道数导致了更大的MAC。&emsp;&emsp;从（1）的公式进行推导，FLOPs的值 B=hwc_{1}c_{2}/g&emsp;&emsp;1x1的分组卷积中MAC和FLOPs的关系为： MAC=hw(c_{1}+c_{2})+\frac{c_{1}c_{2}}{g}=hwc_{1}+\frac{Bg}{c_{1}}+\frac{B}{hw}(2)&emsp;&emsp;g是分组数。从公式中可以看出，在给定输入尺寸$c_{1}\times h\times w$和计算量B，MAC的值与g的值正相关。&emsp;&emsp;为了研究在实践过程中的有效性，我们堆积了10个逐点组卷积来构建基准网络。表2展示了在相同的FLOPs情况下运行速度的差异。从表中可以清晰地看出分组数对运行速度的影响。对比分组数为1和分组数为8的实验结果可以看出，分组数为8的模型运行速度是分组数为1的一倍，在ARM上的数独也慢了30%。&emsp;&emsp;因此，我们建议分组数应该基于目标平台和任务认真选择。简单地增加分组数愚蠢的，因为这在增加准确率的同时也会增加计算量，很可能得不偿失。 G3)分裂网络会减少并行度&emsp;&emsp;在GoogleNet的一系列网络和自动生成网络中，大量采用的了“多径”网络来提高准确率。使用小的操作（分裂网络）来代替一些大网络会带来准确率的提升，但是由于这种操作对大型计算设备如GPU的并行性不是很友好，而且会在内核启动和同步的时候带来额外消耗，因此它会增加计算量。&emsp;&emsp;为了量化分裂网络是如何影响效率的，我们使用不同数量的分类网络制作了一系列网络模块进行实验。每个网络模块包含1-4个1x1的卷积，如何将10个这样的模块堆积在一起组成一个网络，然后它们进行顺序运算或者并行运算。进行的实验效果如表3所示。&emsp;&emsp;表3展示了分裂网络显著地降低了GPU的速度，比如4个分裂网络结构的速度只有1个分类网络结构的1/3。在ARM上的减少相对来说很小。 G4)逐像素操作不可忽视&emsp;&emsp;如图2所示，在轻量级网络中逐像素操作在时间上占据了很大一部分，特别是在GPU上。在我们文章中，逐像素操作包括ReLU，AddTensor，AddBias等等。它们有很小的FLOPs但是在有着很大的MAC。我们将深度卷积也作为逐像素的一员，因为它的MAC与FLOPs的比值很高。&emsp;&emsp;为了验证我们的猜想，我们使用“bottlenecks”单元进行了实验，分别去除ReLU和短路连接，在表4中可以看到实验结果。当两个操作都被去除时，在GPU和ARM上都会得到20%的加速。 结论和讨论&emsp;&emsp;根据上面的指南和研究经验，我们推断一个有效的网络架构需要1）使用平衡的卷积操作（通道相等）；2）关注分组卷积的损失；3）减少分裂的程度；4）减少逐像素操作，这些理想的属性取决于超出理论FLOPs的平台特性（例如内存操作和代码优化）。 3 ShuffleNet V2：一个有效的架构3.1 评价ShuffleNet V1&emsp;&emsp;ShuffleNet是目前先进的网络结构，它被广泛地用于计算能力较低的终端设备比如手机。根据ShuffleNet论文所描述的，目前轻量级网络的主要挑战是在给定计算量的前提下特征通道数量的限制。为了在不提高FLOPs的情况下提高通道数，他们采用了逐点群卷积和bottleneck型的结构。为了提高不同组之间的信息交流，他们使用了通道混洗操作，同时准确率得到提升。根据第二部分的讨论，逐点群卷积和bottleneck结构都会提高MAC(G1和G2)，这个损失是不能忽略的，并且，使用太多的分组也违背了G3，在捷径连接中的逐像素“Add”操作也违背了G4。因此，为了建立一个高效的模型，关键问题是保持与密集卷积相同的通道数，并且不能有太多的分组。 3.2 通道分离和ShuffleNet V2 &emsp;&emsp;根据上面的目的，我们介绍了一种简单的操作名为通道分离（channel split）。在图三(c)中可以看到。在每个单元的开始出，输入通道数c被分成了两个独立的分支c和c’。遵循G3的指导，一个分支独自保留。另一个分支由三个卷积组成并且输入输出通道数遵循G1的原则保持一致。两个1x1卷积部分遵循G2没有进行分组卷积（因为channel split操作分成了两个组）。&emsp;&emsp;卷积之后两个分支被串联（concatnated)，因此通道数保持一致。与ShuffleNet相同的通道混洗操作放到了两个分支串联之后，被用来进行信息交流。&emsp;&emsp;在通道混洗之后，就会开始下个单元。可以注意到ShuffleNet V1中的“Add”操作被取消了。逐像素操作如ReLU和设定卷积只存在一个分支上，并且三个连续的逐像素操作cancat,channel shuffle和channel split被合并成一个逐像素操作。根据G4这种改变是有利的。对于空间下采样，如图3（d），移除了通道分离操作，之后的通道会翻倍。&emsp;&emsp;遵循上面提出的4个指导方针，我们提出了图3（c）（d）这种模块，将其命名为ShuffleNet V2。使用上面的模块进行堆积就会建好网络。为了便利，我们将c’设置为c的一半。整体的网络结构与ShuffleNet v1类似，见表5。唯一的不同之处是：ShuffleNet v1缺少了global averaged pooling层。与ShuffleNet v1相似，我们设置了不同的网络通道数比例来产生不同的网络来适应不同的复杂度。 3.3 网络准确性性分析&emsp;&emsp;ShuffleNet V2网络不仅高效，而且准确，主要两个原因，每个构建模块组成的高效率能够使用更多的特征通道和更大的网络容量。第二个原因是每个模块都会有三分之一的特征通道被直接通过模块进入下一个模块。这可以理解为一种特征重用，在DenseNet和CondenseNet中有相似的部分。在DenseNet中，为了分析特征重用模式，绘制了层间权重的l1范数，如图4（a）所示。很明显，相邻层之间的连接比其他层更强。这意味着所有层之间的密集连接可能引入冗余。最近的CondenseNet也支持这一观点。在ShuffleNet V2中，很容易证明第i和第（i + j）个构建块之间的“直接连接”通道的数量是$r^{j}c$，其中r =（1-c’）/ c。换句话说，特征重用量随着两个块之间的距离呈指数衰减。在远程块之间，特征重用变得更弱。图4（b）绘制了与（a）中类似的可视化，其中r = 0.5。注意，（b）中的模式类似于（a）。因此，ShuffleNet V2通过设计实现了这种特征重用模式，它与DenseNet有着高精度特征重用的相似性，但是它的效率更高，在表8中将证实。 4 实验&emsp;&emsp;我们的消融实验在ImageNet2012的分类数据集上进行，和之前轻量级网络的实验设置相同，所有的网络在四个复杂度上进行比较，分别为40、140、300和500MFLOPs。这些复杂度在移动场景中具有典型性，其它的超参数和协议与ShuffleNet v1相同。我们比较了4种网络： ShuffleNet v1：分组设置为3 MobileNet v2：我们将论文中的准确率与我们复现的准确率都列出来，有一些结果论文中并没有 Xception：原始的Xception非常大，我们采用最近的一个对它进行修改后的衍生版本 DenseNet：原始的网络不适合进行对比实验，我们将表5中的2-4步替换为DenseNet网络的模块进行对比实验，通过调整通道数来控制网络复杂度。 &emsp;&emsp;表8显示了所有结果。我们对结果从不同方面进行分析。&emsp;&emsp;同FLOPs比较速度 &emsp;&emsp;推理速度/(FLOPs/Accuracy)IGV2、IGV3使用通道多，速度慢。 &emsp;&emsp;与其它网络的兼容性 &emsp;&emsp;构成大网络后效果 &emsp;&emsp;目标检测 大的感受野可以增加目标检测的效果（Xception），我们在增加了一个3x3卷积在每个模块的1x1卷积之前，构成ShuffleNet v2*。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>轻量级网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShuffleNet]]></title>
    <url>%2F2019%2F01%2F23%2FShuffleNet%2F</url>
    <content type="text"><![CDATA[[论文地址] 摘要&emsp;&emsp;我们介绍一种被设计用于计算能力有限的移动装置的卷积网络ShuffleNet，新的结构使用逐点群卷积和通道混洗方式，在保持准确率的情况下极大地减少运算量。在一个基于ARM的移动装置中，ShuffleNet在和AlexNet保持相同的准确率的情况下速度提升了13倍。 1 介绍&emsp;&emsp;目前更大更深的网络是主流趋势，主要是为了解决主流视觉识别任务。准确率最高的网络有上百层网络和上千层通道，需要的上百亿的FLOPs(每秒浮点数运算）。这篇报告与之完全对立，在保持最高的准确率的同时把计算量控制在10~100个百万FLOPs内，专注于公共移动平台，如无人机，机器人和智能手机。之前的工作主要致力于剪枝、压缩和使用小存储量代替基础网络结构。我们致力于提出一种新的适用于计算量有限制的基础网络结构。&emsp;&emsp;我们注意到现在最先进的网络如Xception和ResNeXt在小网络的作用及其有限，因为密集的1X1卷积.因此我们提出逐点群卷积来降低1x1卷积的计算复杂度，群卷积会带来一些负面作用，我们使用通道混洗来解决这个问题。基于这两种方法，我们建立了一种高效结构，命名为ShuffleNet。与流行的结构相比，我们的结构可以允许更多的特征图通道在给定计算量的前提下，能够编码更多的信息，这对小网络的表现十分重要。 2 相关工作2.1 高效模型的设计&emsp;&emsp;过去几年深度神经网络在计算机视觉任务上取得了成功，其中模型设计起了很大的作用。在可嵌入设备中运行更大更深的网络的需求不断增加，这激励了高效模型设计的研究。例如，GoogleNet与简单地堆叠卷积层的网络相比，增加了网络的深度并且复杂度更低。SqueezeNet在控制准确率的情况下显著地减少了计算量和参数。ResNet使用有效的bottleneck结构来提升性能。SENet介绍了一种能够花费较小计算量来提升性能的结构单元。 2.2 组卷积&emsp;&emsp;组卷积的概念是AlexNet中提出来的，当时是为了两块GPU进行运算，并且在ResNeXt中证明了其有效性。深度分离卷积在Xception中提出并且分离卷积在Inception系列中得到推广。MobileNet使用深度分离卷积并且在轻量级网络中获得了最先进的结果。我们的工作是推广群卷积和一种新形式的深度分离卷积。 2.3 通道混洗&emsp;&emsp;在我们的认知中，通道混洗在高效网络模型设计中很少被提及。虽然CNNC库cuda-convnet支持随机通道卷积，这个操作相当于在组卷积后进行随机通道交换。这种“随机混洗”有不同的用途但是之后很少有人探索。最近有个two-stage卷积的工作采用了这个方法但是并没有深入研究通道混洗本身以及它在小模型设计上的作用. 2.4 模型加速&emsp;&emsp;这个部分致力于加速推理同时保持预训练模型的准确率。对网络的连接和通道进行剪枝来减少网络在预训练模型的冗余连接以保模型性能。在文献中，量化和因式分解备用来减少冗余计算来加速推理。不修改参数，FFT和其它方法使用卷积方法工具来减少训练的时间消耗。把大网络的知识提炼到小网络，使训练小网络更加简单。 3 方法3.1 对分组卷积的通道混洗&emsp;&emsp;现在的卷积神经网络通常由相同结构组成的重复模块构成。1x1的卷积没有全部采用的原因是1x1卷积需要相当大的复杂度.在小网络中，昂贵的逐点卷积会因复杂度限制而控制通道数量，这可能显著地减少准确率.&emsp;&emsp;解决这个问题的直接方案是通道稀疏连接，比如包括1x1卷积的分组卷积。确保每个输入通道组上进行相应的卷积，组卷积就会显著地降低计算成本。但是这会带来新的问题：一些通道的输出仅仅来源于输入通道的一小部分。图1（a）说明了这种情况。很明显地看出，每个输出组只与它的输入组之间有联系。这个特性阻隔了通道组和弱表示的信息流动。&emsp;&emsp;如果我们允许分组卷积可以从不同的组中获得输入数据，(如Figure1(b)),输入通道和输出通道就会全部建立联系。对于上一层分组卷积产生的特征图，我们可以把每个组的通道分离成更小的组，然后将这些组随机排序作为下一层网络每个组的输入。这个操作可以使用通道卷积方便快捷地实现（如Figure1（c））：计算拥有$g*n$个通道数g个组的卷积层；我们需要先将数据改变形状变为$(g,n)$,然后转换和扁平化作为下一层的输入。在其中我们注意到这个操作在经过两层不同分组的卷积后依然有效。更重要的是，通道混洗过程是十分微小的，这意味着它能够嵌入到端对端的网络训练中。&emsp;&emsp;通道混洗操作使得使用大量分组卷积层的有效网络变得可能.在下一个部分我们将介绍一个使用分组卷积和通道混洗结构的有效的网络单元。 3.2 ShuffleNet单元&emsp;&emsp;基于通道混洗操作的优点，我们提出了专门为小网络设计的新结构ShuffleNet单元。我们的设计基于ResNet的bottleneck模块（如Figure2（a））。这是一个残差模块。在他的残差分支中，我们在bottleneck模块的特征图提取模块采用了适合运算的3x3的深度卷积。之后，我们将第一个1x1卷积替代为逐点群卷积，之后进行通道混洗，这样来组成ShuffleNet单元，如Figure2（b）。第二个逐点群卷积的作用是将通道恢复到与捷径路线相同的尺寸。简单来说，我们在第二个逐点群卷积后并没有采用通道混洗，因为采用与否对结果没有影响。在ShuffleNet单元哪个位置设置步长的问题上，我们简单地进行了两个修改（如Figure2（c））：在捷径路线上添加3x3的平均值池化层；使用通道级联（channel concatenation)代替元素相加，这样可以在很少的额外计算下扩大通道尺寸。&emsp;&emsp;与ResNet和RexNeXt相比较，我们的模型有更少的计算量。输入为c*h*wbottleneck通道数为m,ResNet单元要求hw(2cm+9m^2)FLOPs，ResNeXt单元要求hw(2cm+9m^2/g)FLOPs。ShuffleNet单元需要hw(2cm/g+9m)FLOPs，g是卷积的分组数。换句话说，在相同的计算量预算下，ShuffleNet可以使用更广泛的特征图。我们发现这对小网络是十分重要的，因为小网络在获取信息的过程中通道数量是不足的。&emsp;&emsp;另外，ShuffleNet深度卷积仅应用于bottleneck特征图。虽然深度卷积在理论上有很少的计算量，但我们发现将它移植到低功耗的移动设备上是十分困难的，与其他密集网络相比，ShuffleNet网络可能会在计算与内存存取上存在不平衡。 3.3 网络结构&emsp;&emsp;基于ShuffleNet单元，我们建立了如Table 1的ShuffleNet网络结构。提出的网络主要是由三个阶段聚集组成的ShuffleNet单元组成的。每个阶段首先建立的模块采用的步长为2.其它的超参数设置相同，并且下一个阶段的输出通道数翻倍。我们将bottleneck的通道数设置为输出通道的1/4.我们打算提供一种尽可能简单的基本设计，尽管我们发现进一步的超参数设置可能会带来更好的结果。&emsp;&emsp;在ShuffleNet单元中，分组数g控制着逐点卷积的稀疏性。Table 1展示了不同组数的效果，我们采用的输出通道数尽可能使复杂度不变。效果十分明显，在相同的复杂度下大的分组导致更多的输出通道（这也意味着更多的卷积核），这意味着在输入通道有限的情况下大分组可以编码更多的信息。&emsp;&emsp;Table 1是网络的完全体，之后的ShuffleNets*意味着网络的复杂度大致是原网络的$s^2$. 4 实验]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>轻量级网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MobileNetV2 倒置残差和线性瓶颈]]></title>
    <url>%2F2019%2F01%2F23%2FMoblieNetV2%2F</url>
    <content type="text"><![CDATA[参考博客论文地址 摘要&emsp;&emsp;在本文中，我们描述了一种新的移动网络结构MobileNetV2，它提高了移动网络在多类型任务和基准以及不同网络尺寸范围的最佳性能。我们还介绍了一种有效地使用轻量级网络进行目标检测的新颖架构SSDLite。并且我们将Deeplabv3进行修剪后构建出一种用于移动语义分割的模型，称为Mobile Deeplabv3。&emsp;&emsp;MobileNetV2基于倒置残差结构，并且在窄boottleneck层中有快捷连接。中间的扩大层使用轻量级的深度卷积来过滤特征作为非线性的来源。另外，我们发现在窄层中去除非线性来保持表现能力是很重要的，我们证明了这可以提高性能并且直观地启发了我们网络的设计。&emsp;&emsp;最后，我们的方法允许输入/输出域与转换的表达性分离，这为进一步分析提供了方便的框架。我们测量我们在ImageNet分类，COCO物体检测，VOC图像分割上的表现。我们评估准确性与乘法加法（MAdd）测量的操作次数，实际延迟和参数数量之间的权衡。 1 介绍&emsp;&emsp;神经网络在机器智能领域有革命性地作用，比如在图像识别任务中超过了人类的识别准确率。然而，提高准确率的同时带来了新的代价：先进的网络需要的高计算能力超越了许多手机和嵌入式应用计算能力。&emsp;&emsp;本文介绍了一种新的为移动和资源受限环境特殊定制的神经网络结构。我们的网络在保持相同准确率的情况下通过减少计算量和内存需求，推动了移动定制计算机视觉模型的水平。&emsp;&emsp;我们主要贡献是一种新的层模块：具有线性瓶颈的倒置残差。这个模块采用了一种低维的压缩表示作为输入，首先扩展成高维然后使用轻量级深度卷积过滤。随后使用线性卷积将特征投影回低维表示。官方实现TensorFlow-Slim提供一部分操作。&emsp;&emsp;该模块可以在任何现代框架中使用标准操作有效地实现，并允许我们的模型使用标准基准测试在多个性能点上击败最新技术。此外，这种卷积模块特别适用于移动设计，因为它可以通过永远不会完全实现大型中间张量来显着减少推理期间所需的内存占用。这减少了许多嵌入式硬件设计中对主存储器访问的需求，这些设计提供了少量非常快速的软件控制的高速缓冲存储器。 2 相关工作&emsp;&emsp;在最近几年，调整深度神经网络的架构以在准确率和性能之间有一个最佳平衡成为一个积极研究的领域。早期的网络如AlexNet,VGGNet,GoogLeNet以及ResNet，这些网络的设计都进行了大量的手工体系结构搜索和训练算法改进。最近在网络架构探索上有了很多进展，比如超参数还有各种网络修剪方法以及连通性学习。大量的工作也致力于内部卷积模块的连接架构的改变，比如ShuffleNet[20]或引入了稀疏性[21]和其它[22]。&emsp;&emsp;最近，[23, 24, 25, 26]引入了架构探索的新方向，将遗传算法和强化学习加入了其中。然而一个缺点是得到的网络最终会十分复杂。本文的目的是找到然后是神经网络更好地运作并用它指导最简单的网络设计。我们的方法应该被视为[23]描述方法的一种互补和相近的工作。在这种情况下，我们的方法类似于[20,22]所采用的方法并允许进一步改善性能，同时提供内部操作的一部分。我们的网络设计基于MobileNetV1。保留了它的简洁性而且不要求任何特殊操作就能显著提升准确率，实现了移动应用的多图像分类和检测任务的最新技术。 3 预备、讨论和直觉3.1 深度可分离卷积&emsp;&emsp;深度可分离卷积是现在很多高效神经网络模块的关键部分，并且我们也将其应用到我们的网络中。基础思想是使用分解的版本代替全卷积层，将全卷积层分为深度卷积和点卷积两个部分。第一次深度卷积是使用单个卷积滤波器在每个输入通道上进行轻量级滤波。第二次点卷积使用1x1的卷积主要负责通过计算输入通道的线性组合来建立新的特征。&emsp;&emsp;标准卷积在输入通道为$d_{i}$输出通道为$d_{j}$，卷积和大小为$k\times k$的情况下计算量为$h\times w\times d_{i}\times d_{j}\times k^2$。深度可分离卷积的计算量为 h*w*d_{i}*(k^2+d_{j})(1)，实验证实深度可分离卷积在性能上与常规卷积几乎相同，但计算量大致变为原来的$1/k^2$。我们使用的k为3。 3.2 线性瓶颈&emsp;&emsp;思考一个深度神经网络由n层组成$L_{i}$，每个$L_{i}$有h_{i}*w_{i}*d_{i}激活张量。这节我们讨论这些张量的基础特性，我们将这些张量视为$h_{i}*w_{i}$个像素点的$d_{i}$维的容器。非正式地，对于一个真实图片的输入集合，我们说激活层集合组成了“多方面兴趣”。长期以来，人们一直以为神经网络的多方面兴趣可以嵌入到低维的子空间中。换句话说，当我们查看深度卷积层的所有单个d通道像素时，在这些值中编码的信息实际上位于某些流形中，而这些流形又可嵌入到低维子空间中。&emsp;&emsp;乍一看，这些事实可以简单地通过减少层的尺寸来捕获和利用从而减少操作空间的尺寸。这在MobileNetV1中成功地通过宽度乘数有效地平衡计算量和准确率。遵循这种直觉，这种宽度乘数方法允许人们减少激活空间的尺寸，直到感兴趣的流体经过整个空间。然而，当我们回想深度卷积网络实际上在每次坐标变换时都有非线性时比如ReLU，这种直觉会崩溃。例如，应用于1D空间中的线的ReLU产生“射线”，与在Rn空间中一样，它通常产生具有n关节的分段线性曲线。&emsp;&emsp;很容易看出，在通常情况下，ReLU转换层的结果有非零的体积S，通过对输入进行线性转换B获得测绘内部S的点，这意味部分对应于全维输出的输入空间受限于线性变换。换句话说，深度网络仅仅在非零部分具有线性分类器的能力。&emsp;&emsp;在另一方面当ReLU合并通道时，必然会损失通道信息。但是我们如果有很多通道，并且激活流形中有一个机构，那么信息可能会保留在其它通道中。在附录中，我们展示了如果输入流形能够被嵌入到激活空间的显著低维子空间中，之后ReLU变换会保留信息同时在可表达功能集中引入所需的复杂性。&emsp;&emsp;总而言之，我们强调了两个属性，这两个属性表明感兴趣的流形应位于高纬度激活空间的低纬度子空间： 1.如果感兴趣的流形在ReLU变换后保持了非零量，与线性变换相同。 2.ReLU在保留输入流形的全部信息是十分重要的，但是仅在输入流形位于输入空间的低维子空间时有效。 &emsp;&emsp;这两个见解为我们提供了优化存在的神经网络结构的经验暗示：假如感兴趣的流形是低维的，我们能够在卷积模块中插入线性瓶颈来捕获它。通过实验证明，线性模块是十分重要的，因为它阻止非线性破坏太多信息。在第六节中，我们凭经验证明，在瓶颈中使用非线性层确实会使性能受到几个百分点的影响，从而进一步验证了我们的假设3。 我们注意到在[29]中报告了有助于非线性的类似报告，其中从传统残差块的输入中去除了非线性并且导致CIFAR数据集的性能提高。&emsp;&emsp;对于本文的其余部分，我们将利用瓶颈卷积。 我们将输入瓶颈尺寸与内部尺寸之间的比率称为膨胀比。 3.3 残差倒置&emsp;&emsp;瓶颈网络和残差块十分相似，其中每个块包含一个输入，之后是几个瓶颈，然后是扩展。然而，受到瓶颈模块实际上包含所有必要信息的直观启发，虽然扩展层仅仅作为伴随张量的非线性变换的实现细节，但我们在瓶颈之间直接使用快捷方式。&emsp;&emsp;图3提供了设计差异的示意图。 插入快捷方式的动机类似于经典残差连接的动机：我们希望提高梯度在乘数层上传播的能力。 然而，倒置设计的内存效率要高得多（详见第5节），并且在我们的实验中效果稍好一些。&emsp;&emsp;瓶颈卷积的运行时间和参数数量。基本结构如表一所示。对于大型为$h\times w$的块，扩展因子为t，内核大小为k，输入通道为$d^{‘}$输出通道为$d^{‘’}$，矩阵乘法计算总量为 h*w*d^{'}*t(d^{'}+k^{2}+d^{''})与（1）相比多了额外的项,因为我们确实有一个额外的1×1卷积，但是我们网络的性质允许我们使用更小的输入和输出维度。 在表3中，我们比较了MobileNetV1，MobileNetV2和ShuffleNet之间每个分辨率所需的大小。 3.4 信息流动的说明&emsp;&emsp;我们的架构有个很有趣的特性：它能够对构建块（瓶颈块）的输入输出域进行自然分离，这是一种将输入转换为输出的非线性函数。前者可以看出每层网络的容量，后者可以看做是表现能力。这与传统的卷积模块存在差异，包括常规网络和分离网络，它们的容量和表现力混在一起并且是输出层深度的函数。&emsp;&emsp;特别是，在我们的例子中，当内层深度为0时，由于快捷连接，底层卷积是身份函数。当膨胀比小于1时，这是一个经典的残余卷积块[8,30]。但是，出于我们的目的，我们表明膨胀率大于1是最有用的。&emsp;&emsp;这种解释使我们能够将网络的表现力与其容量分开研究，并且我们认为有必要进一步探索这种分离，以便更好地理解网络属性。 4 网络结构&emsp;&emsp;现在描述我们的网络细节。如前面所述的基础模块是带有残差模块的深度可分离卷积。模块细节在表一。MobileNetV2的结构包括32层滤波器，如表二所示结构，有19层residual bottleneck(17?)。我们使用ReLU6做非线性计算，因为它在低精度运算上有很好的鲁棒性。我们使用3x3的卷积核，并且使用dropout和batch normalization。&emsp;&emsp;除第一层外，我们在整个网络中使用恒定的扩展速率。在我们的实验中，我们发现5到10之间的扩展速率导致几乎相同的性能曲线，较小的网络通过略小的扩展速率获得更好的结果，而较大的网络具有稍微更好的性能和更大的扩展速率。&emsp;&emsp;对于我们所有的主要实验，我们使用应用于输入张量大小的扩展因子6。例如，对于采用64通道输入张量并产生具有128个通道的张量的瓶颈层，中间扩展层则为64·6 = 384个通道。&emsp;&emsp;平衡超参数：我们通过使用输入图像分辨率和宽度乘数作为可调超参数来定制我们的架构到不同的性能点，可以根据所需的精度/性能权衡进行调整。 我们的主要网络（宽度乘数1,224×224）具有3亿乘法的计算成本，并使用340万个参数。我们探索性能权衡，输入分辨率从96到224，宽度乘数从0.35到1.4。网络计算成本范围从7M MAdds到585M MAdds，而模型大小在1.7M和6.9M参数之间变化。&emsp;&emsp;一个小的实现差异，[27]是对于小于1的乘数，我们将宽度乘数应用于除最后一个卷积层之外的所有层。这可以提高较小网络的性能。 5 实验记录5.1 存取效率推断&emsp;&emsp;内存的大小由瓶颈张量的大小决定，而不是瓶颈内部张量的大小决定的（并且更大）。&emsp;&emsp;我们的瓶颈残差模块先扩展后压缩。 6 实验6.1 ImageNet分类&emsp;&emsp;训练设置：我们使用TensorFlow训练我们的模型[31]。 我们使用标准的RMSPropOptimizer，将衰减和动量设置为0.9。我们在每一层之后使用批量标准化，标准重量衰减设置为0.00004。在MobileNetV1 [27]设置之后，我们使用0.045的初始学习率和每个时期0.98的学习率衰减率。我们使用16个GPU异步工作器，批量大小为96。 &emsp;&emsp;结果:我们将我们的网络与MobileNetV1，ShuffleNet和NASNet-A模型进行比较。表4显示了一些选定模型的统计数据，其完整性能图如图5所示。 6.2 目标检测&emsp;&emsp;我们评估和比较MobileNetV1和MobileNetV2在SSD在COCO数据集上中特征提取的性能，我们也比较了YOLOv2和单个SSD作为基准。&emsp;&emsp;SSDLite：我们将SSD的预测层的常规卷积全部替换为深度分离卷积，这种模型适用于移动设备，称为SSDlite，SSDlite显著地减少了计算量和参数，如表5所示。表6显示了所有的计算结果。 6.3 语义分割6.4 强化学习7 讨论和未来工作]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>轻量级网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.博客搭建参考next主题使用教程多终端同步教程主题美化hexo中使用Mathjax科学上网 快速开始创建一个新的文章1hexo new "My New Post" More info: Writing 运行服务1hexo server More info: Server 生成静态文件1hexo generate More info: Generating 部署到远程站点1hexo deploy 发布文章1hexo d --g More info: Deployment 添加图片在目标的.comfig.yml文件的38行修改数据，可以在新建博客的同时新建一个资源文件夹来放置图片，博客引用时直接使用![picture](picture_name) 数学公式行内效果为(a+b+c)^2独自一行公式需要使公式独占一行效果为 (a+b+c)^2]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习笔记]]></title>
    <url>%2F2019%2F01%2F23%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[培养专注的习惯，学会独立思考 1 学习AI需要哪些技能 1.编程基础 熟练使用linux，git，vim等环境和工具。 熟练掌握 C/C++、Python等编程语言。 熟练掌握cmake，g++等编译工具。 2.算法基础 熟悉传统图像算法，机器学习算法。 熟练跟踪并阅读行业前沿研究，复现结果。 系统性熟悉深度学习理论。 3.框架基础 熟练掌握 Caffe、TensorFlow、pytorch等以及不断新出的开源平台。 4.其它基础 掌握爬虫等前后端的基础知识。 了解并熟悉Cuda等GPU编程技术，了解一些移动端的硬件知识。 了解并熟悉 Android、iOS 等移动端的基础知识，在项目中可能会需要使用。 2 吴恩达深度学习课后作业吴恩达深度学习视频作业参考 2.1 神经网络和深度学习2.1.1 logistic回归作业代码 2.1.2 浅层神经网络作业代码 2.1.3 深层神经网络作业代码 2.2 改善深层神经网络2.2.1 深度学习的实用层面3 cs231n课程笔记3.1 图像处理的一些简单方法12345678910from PIL import Imagefrom PIL import ImageEnhanceimport matplotlib.pyplot as plt# 原始图像image = Image.open('match_learning/picture/1.jpg') # 打开图片# image.show()plt.figure("origan_image")plt.imshow(image)plt.show() 123456789# 亮度增强enh_bri = ImageEnhance.Brightness(image)brightness = 1.5image_brightened = enh_bri.enhance(brightness)# image_brightened.show()plt.figure("brightened")plt.imshow(image_brightened)plt.show()image_brightened.save('match_learning/picture/image_brightened.jpg') 123456789# 色度增强enh_col = ImageEnhance.Color(image)color = 1.5image_colored = enh_col.enhance(color)# image_colored.show()plt.figure("colored")plt.imshow(image_colored)plt.show()image_colored.save('match_learning/picture/image_colored.jpg') 123456789# 对比度增强enh_con = ImageEnhance.Contrast(image)contrast = 1.5image_contrasted = enh_con.enhance(contrast)# image_contrasted.show()plt.figure("contrast")plt.imshow(image_contrasted)plt.show()image_contrasted.save('match_learning/picture/image_contrasted.jpg') 123456789# 锐度增强enh_sha = ImageEnhance.Sharpness(image)sharpness = 1.5image_sharped = enh_sha.enhance(sharpness)# image_sharped.show()plt.figure("sharpness")plt.imshow(image_sharped)plt.show()image_sharped.save('match_learning/picture/image_sharped.jpg') 3.2 python学习笔记]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>编程</tag>
        <tag>笔记</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
</search>
